{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f72ccb6",
   "metadata": {},
   "source": [
    "- 순환신경망 종류\n",
    "    * 심플 순환신경망(Simple RNN) 단점\n",
    "        - 긴 문장(단어의 갯수가 많은 경우)을 학습하기 어려움\n",
    "        - 문장이 길 수록(단어의 갯수가 많을 수록) 초반의 정보(단어를 의미함)는 점진적으로 희석(소멸)됨\n",
    "        - 즉, 멀리 떨어져 있는 단어의 정보를 인식하는데 어려움이 있음\n",
    "            - 문장의 앞뒤 문맥(단어를 의미함) 데이터의 기억이 단기기억으로 저장됨\n",
    "    - 이러한 단점을 보완한 모델이 LSTM 임\n",
    " \n",
    "    * 장기기억 순환신경망(Long Shot-Term Memory, LSTM)\n",
    "        - Simple RNN의 단점을 보완한 모델\n",
    "        - 단기기억을 오래 기억할 수 있도록 고안된 모델\n",
    "        - 많은 이전 단어들의 정보를 기억해야 하기 때문에 훈련 속도가 느림(단점)\n",
    "        - 시스템 저장 공간이 많이 필요함(단점)\n",
    " \n",
    "    * 게이트웨이 반복 단위 순환신경망(Gated Recurrent Unit, GRU)\n",
    "        - LSTM의 장기기억 순환신경망의 개념을 그대로 적용하고, 단점을 보완한 모델\n",
    "        - 너무 오래된 기억은 서서히 소멸해 나가면서, 최근 기억을 지속적으로 유지하는 방식을 사용함\n",
    "        - 성능은 LSTM과 동일 (속도를 빠르게 하기 위한 모델임)\n",
    " \n",
    "    * RNN 순환신경망 모델들은 주로, RMSprop 옵티마이저를 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf626b5",
   "metadata": {},
   "source": [
    "### 라이브러리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecece4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "### 사용할 데이터셋\n",
    "# - 영화 리뷰 감상평 데이터(긍정/부정)\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "### 텍스트 길이 정규화 라이브러리\n",
    "# - 텍스트의 길이가 긴경우 자르고, 길이가 작은 경우에는 채움\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05472f",
   "metadata": {},
   "source": [
    "### 데이터 읽어 들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2293e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "### 데이터 수집\n",
    "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124aa2c",
   "metadata": {},
   "source": [
    "### 훈련 : 검증 = 8 : 2로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0bc555",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 변수명 : train_input, train_target, val_input, val_target\n",
    "train_input, val_input, train_target, val_target = train_test_split(\n",
    "    train_input, train_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9a030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,) (20000,)\n",
      "(5000,) (5000,)\n",
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, train_target.shape)\n",
    "print(val_input.shape, val_target.shape)\n",
    "print(test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4b6b0",
   "metadata": {},
   "source": [
    "### 데이터 스케일링하기(단어 길이 표준화하기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a752bb8",
   "metadata": {},
   "source": [
    "- 제거 및 채우기 속성\n",
    "- truncating : maxlen보다 클 때 자르기 속성\n",
    "    - truncating=\"pre\" : 앞쪽 제거(기본값으로 사용됨, 생략가능)\n",
    "    - truncating=\"post\" : 뒤쪽 제거\n",
    "* padding : maxlen보다 작을 때 채우기 속성\n",
    "    - padding=\"pre\" : 앞쪽을 0으로 채우기 (기본값으로 사용됨, 생략가능)\n",
    "    - padding=\"post\": 뒤쪽을 0으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8d2a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n",
      "(5000, 100)\n"
     ]
    }
   ],
   "source": [
    "### 텍스트 제거 또는 채우기 속성 추가\n",
    "### 훈련 데이터 스케일링\n",
    "train_seq = pad_sequences(train_input, maxlen=100, truncating=\"post\", padding=\"post\")\n",
    "print(train_seq.shape)\n",
    "\n",
    "### 검증 데이터 스케일링\n",
    "val_seq = pad_sequences(val_input, maxlen=100, truncating=\"post\", padding=\"post\")\n",
    "print(val_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f24aa3",
   "metadata": {},
   "source": [
    "### LSTM 훈련모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4636a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1e4d74655e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 입력계층 (임베딩 계층) 추가하기\n",
    "model.add(\n",
    "    keras.layers.Embedding(input_dim=500, output_dim=16, input_length=100)\n",
    ")\n",
    "### 은닉계층 (LSTM 계층) 추가하기 : RNN 모델의 이름만 바꿔주면 됨\n",
    "model.add(\n",
    "    keras.layers.LSTM(units=8)\n",
    ")\n",
    "\n",
    "### 출력계층 추가하기\n",
    "model.add(\n",
    "    keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e30e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           8000      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8)                 800       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,809\n",
      "Trainable params: 8,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207e128",
   "metadata": {},
   "source": [
    "- Param 계산공식\n",
    "    * embedding = 말뭉치갯수 * 출력갯수 = 500 * 16 = 8,000\n",
    " \n",
    "    * LSTM = 가중치 세트 갯수 * (출력갯수 * (입력갯수 + 출력갯수 + 1))\n",
    "        -  = 4 * (8 * (16 + 8 + 1)) = 800\n",
    "        \n",
    "- 가중치 세트 설명\n",
    "    - 총 4개의 세트로 구성되어 있음(이때 세트를 -> 게이트라고 칭함)\n",
    "  \n",
    "* 셀상태관리\n",
    "    - LSTM의 장기 기억을 담당\n",
    "    - 셀 상태는 정보를 장기간 동안 유지할 수 있도록 관리됨\n",
    "    - 입력/망각/출력 게이트를 통해서 셀 상태 정보가 업데이트\n",
    " \n",
    "* 입력게이트\n",
    "    - 현재 시점의 입력 데이터(단어를 의미함)가 셀 상태에 얼마나 반영될지를 결정\n",
    "    - 새로운 정보를 얼마나 저장할지를 조절하는 역할을 수행\n",
    " \n",
    "* 망각게이트\n",
    "    - 이전 셀 상태에서 얼마나 많은 정보를 잊어버릴지 결정\n",
    "    - 이전 상태의 정보를 얼마나 제거할지를 조절하는 역할\n",
    " \n",
    "* 출력게이트\n",
    "    - 셀 상태에서 어떤 정보를 출력할지 결정\n",
    "    - 셀 상태를  현재 시점의 출력으로 변환하는 역할\n",
    " \n",
    "* 가중치 업데이트 : 위 4개의 가중치 세트가 동시에 작동하면서 출력에 가장 가까운 단어 조합을 만들어 냄\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0a20b",
   "metadata": {},
   "source": [
    "### 훈련모델 설정하기(compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e53fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### rmsprop 사용, 학습율 0.0001 사용, 정확도 출력\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51bacf",
   "metadata": {},
   "source": [
    "### 콜백함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488a319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### rmsprop 사용, 학습율 0.0001 사용, 정확도 출력\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"./model/best_LSTM_model.h5\", save_best_only=True\n",
    ")\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(\n",
    "    patience=3, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6829c",
   "metadata": {},
   "source": [
    "### 모델 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983927d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 6s 9ms/step - loss: 0.6931 - accuracy: 0.5045 - val_loss: 0.6930 - val_accuracy: 0.5122\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6928 - accuracy: 0.5372 - val_loss: 0.6927 - val_accuracy: 0.5350\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6923 - accuracy: 0.5594 - val_loss: 0.6921 - val_accuracy: 0.5450\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6914 - accuracy: 0.5685 - val_loss: 0.6907 - val_accuracy: 0.5820\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6891 - accuracy: 0.5972 - val_loss: 0.6865 - val_accuracy: 0.6212\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6754 - accuracy: 0.6291 - val_loss: 0.6531 - val_accuracy: 0.6666\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6390 - accuracy: 0.6883 - val_loss: 0.6261 - val_accuracy: 0.6976\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6163 - accuracy: 0.7136 - val_loss: 0.6086 - val_accuracy: 0.7096\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5987 - accuracy: 0.7273 - val_loss: 0.5938 - val_accuracy: 0.7218\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5812 - accuracy: 0.7409 - val_loss: 0.5783 - val_accuracy: 0.7326\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5643 - accuracy: 0.7487 - val_loss: 0.5641 - val_accuracy: 0.7410\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5480 - accuracy: 0.7561 - val_loss: 0.5500 - val_accuracy: 0.7484\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5339 - accuracy: 0.7626 - val_loss: 0.5412 - val_accuracy: 0.7430\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5220 - accuracy: 0.7688 - val_loss: 0.5342 - val_accuracy: 0.7494\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5118 - accuracy: 0.7710 - val_loss: 0.5243 - val_accuracy: 0.7570\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5030 - accuracy: 0.7739 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4960 - accuracy: 0.7775 - val_loss: 0.5175 - val_accuracy: 0.7536\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4903 - accuracy: 0.7805 - val_loss: 0.5162 - val_accuracy: 0.7590\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4852 - accuracy: 0.7810 - val_loss: 0.5098 - val_accuracy: 0.7606\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4806 - accuracy: 0.7845 - val_loss: 0.5066 - val_accuracy: 0.7614\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4772 - accuracy: 0.7868 - val_loss: 0.5061 - val_accuracy: 0.7596\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4743 - accuracy: 0.7836 - val_loss: 0.5035 - val_accuracy: 0.7598\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4718 - accuracy: 0.7850 - val_loss: 0.5011 - val_accuracy: 0.7672\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4688 - accuracy: 0.7869 - val_loss: 0.4994 - val_accuracy: 0.7640\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4669 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7642\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4650 - accuracy: 0.7876 - val_loss: 0.4968 - val_accuracy: 0.7654\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4627 - accuracy: 0.7868 - val_loss: 0.4975 - val_accuracy: 0.7640\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4614 - accuracy: 0.7878 - val_loss: 0.5060 - val_accuracy: 0.7584\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4602 - accuracy: 0.7878 - val_loss: 0.4942 - val_accuracy: 0.7608\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4589 - accuracy: 0.7869 - val_loss: 0.4958 - val_accuracy: 0.7672\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4573 - accuracy: 0.7885 - val_loss: 0.4914 - val_accuracy: 0.7618\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4567 - accuracy: 0.7879 - val_loss: 0.4937 - val_accuracy: 0.7650\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.4931 - val_accuracy: 0.7648\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4543 - accuracy: 0.7891 - val_loss: 0.4900 - val_accuracy: 0.7632\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4539 - accuracy: 0.7879 - val_loss: 0.4908 - val_accuracy: 0.7650\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4529 - accuracy: 0.7889 - val_loss: 0.4931 - val_accuracy: 0.7662\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4522 - accuracy: 0.7886 - val_loss: 0.4912 - val_accuracy: 0.7636\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_seq, train_target, epochs=100, batch_size=64,\n",
    "    validation_data=(val_seq, val_target),\n",
    "    callbacks=[checkpoint_cb, earlystopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea904ab0",
   "metadata": {},
   "source": [
    "### 최적의 모델 읽어들여서 훈련/검증/테스트 성능 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d476e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 3ms/step - loss: 0.4541 - accuracy: 0.7906\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.4900 - accuracy: 0.7632\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4794 - accuracy: 0.7671\n"
     ]
    }
   ],
   "source": [
    "### 최적의 모델\n",
    "best_model = keras.models.load_model(\"./model/best_LSTM_model.h5\")\n",
    "\n",
    "train_score = best_model.evaluate(train_seq, train_target)\n",
    "val_score   = best_model.evaluate(val_seq, val_target)\n",
    "\n",
    "### 테스트 데이터는 -> 스케일링 처리 후 성능검증하기...\n",
    "test_seq = pad_sequences(test_input, maxlen=100, truncating=\"post\", padding=\"post\")\n",
    "test_score  = best_model.evaluate(test_seq, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk_dl_gpu_kernel",
   "language": "python",
   "name": "pk_dl_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
