{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25dc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "### 텍스트 길이 정규화 라이브러리\n",
    "# - 텍스트의 길이가 긴경우 자르고, 길이가 작은 경우에는 채움\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "### 말뭉치 사전 처리를 위한 라이브러리\n",
    "# - 텍스트 데이터를 숫자(인덱스번호)로 변환하는 라이브러리\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce97cbf",
   "metadata": {},
   "source": [
    "### 사용할 데이터셋 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe8bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 질문\n",
    "questions = [\n",
    "    \"전기요금 어때?\",\n",
    "    \"전기요금 알려줘\",\n",
    "    \"안녕하세요\",\n",
    "    \"안녕\",\n",
    "    \"너 이름이 뭐니?\",\n",
    "    \"이름이 뭐야\",\n",
    "    \"어떻게 지내세요?\",\n",
    "    \"프랑스의 수도는 어디인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"가장 감명 깊게 본 영화는 무엇인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"전기요금 어때?\",\n",
    "    \"안녕하세요\",\n",
    "    \"너 이름이 뭐니?\",\n",
    "    \"어떻게 지내세요?\",\n",
    "    \"프랑스의 수도는 어디인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"가장 감명 깊게 본 영화는 무엇인가요?\",\n",
    "    \"뭐 해?\",\n",
    "    \"오늘 날씨 어때?\",\n",
    "    \"좋아하는 음식은 뭐에요?\",\n",
    "    \"무슨 일을 좋아해요?\",\n",
    "    \"가장 좋아하는 색깔은 무엇인가요?\",\n",
    "    \"가장 기억에 남는 여행은 어디에요?\",\n",
    "    \"주말에는 뭐하고 시간을 보내나요?\",\n",
    "    \"좋아하는 음악 장르가 있나요?\",\n",
    "    \"가장 좋아하는 동물은 무엇인가요?\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\"\n",
    "]\n",
    "\n",
    "### 답변\n",
    "answers = [\n",
    "    \"전기요금이 계속 인상되고 있어요!\",\n",
    "    \"전기요금이 계속 인상되고 있어요!\",\n",
    "    \"안녕하세요! 반가워요^^\",\n",
    "    \"안녕하세요! 반가워요^^\",\n",
    "    \"제 이름은 챗봇이에요.\",\n",
    "    \"제 이름은 챗봇이에요.\",\n",
    "    \"저는 잘 지내고 있어요, 감사합니다!\",\n",
    "    \"프랑스의 수도는 파리에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"전기요금이 계속 인상되고 있어요!\",\n",
    "    \"안녕하세요! 반가워요^^\",\n",
    "    \"제 이름은 챗봇이에요.\",\n",
    "    \"저는 잘 지내고 있어요, 감사합니다!\",\n",
    "    \"프랑스의 수도는 파리에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\",\n",
    "    \"일하고 있어요.\",\n",
    "    \"오늘은 맑아요.\",\n",
    "    \"제가 좋아하는 음식은 피자에요.\",\n",
    "    \"일을 하는 것을 좋아해요.\",\n",
    "    \"제가 가장 좋아하는 색깔은 파란색이에요.\",\n",
    "    \"가장 기억에 남는 여행은 파리에 다녀온 것이에요.\",\n",
    "    \"주말에는 쉬면서 책을 읽거나 친구들과 만나요.\",\n",
    "    \"저는 다양한 음악을 즐겨듣습니다.\",\n",
    "    \"가장 좋아하는 동물은 강아지에요.\",\n",
    "    \"가장 감명 깊게 본 영화는 '인셉션'이에요.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee51e45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 52)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 질문/답변 갯수 확인하기\n",
    "len(questions), len(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88a47c",
   "metadata": {},
   "source": [
    "### 단어사전(말뭉치) 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30cde1d",
   "metadata": {},
   "source": [
    "- 말뭉치 사전\n",
    "    - 데이터셋에 있는 모든 문장(질문+답변) 내에 단어들을 추출하여\n",
    "    - 빈도가 가장 높은 단어 순으로 번호(인덱스)를 부여하여 관리함\n",
    "    - 고유한 단어들만으로 구성된 사정을 의미\n",
    "    - 문장에서 단어를 추출하여 번호를 부여하는 것 -> 토큰화(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c595d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x217e082f7f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 텍스트 문장 데이터를 토큰화(단어로 분리하여 숫자 인덱스화)를 위한 클래스 생성\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb45870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 토큰화 함수 : fit_on_texts\n",
    "# - 텍스트에서 단어 추출 및 인덱스화\n",
    "# - 질문 및 답변의 모든 문장 내에 단어들을 인덱스화해야 함\n",
    "#    -> 질문과 답변의 각각의 리스트를 더하기 연산하여 하나의 리스트로 사용\n",
    "# - 문장내 단어들을 모두 추출하여 빈도가 가장 높은 순서대로 1부터 인덱스 번호가 부여됨\n",
    "# - 문장내 단어의 분리 -> 띄어쓰기 기준으로 분리함\n",
    "tokenizer.fit_on_texts(questions + answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244370e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 전체 분리된 단어들의 갯수 확인하기\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376f99c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가장': 1,\n",
       " '좋아하는': 2,\n",
       " '무엇인가요': 3,\n",
       " '있어요': 4,\n",
       " '음식은': 5,\n",
       " '일을': 6,\n",
       " '좋아해요': 7,\n",
       " '색깔은': 8,\n",
       " '기억에': 9,\n",
       " '남는': 10,\n",
       " '여행은': 11,\n",
       " '주말에는': 12,\n",
       " '동물은': 13,\n",
       " '제가': 14,\n",
       " '어때': 15,\n",
       " '감명': 16,\n",
       " '깊게': 17,\n",
       " '본': 18,\n",
       " '영화는': 19,\n",
       " '저는': 20,\n",
       " '안녕하세요': 21,\n",
       " '프랑스의': 22,\n",
       " '수도는': 23,\n",
       " '뭐': 24,\n",
       " '해': 25,\n",
       " '오늘': 26,\n",
       " '날씨': 27,\n",
       " '뭐에요': 28,\n",
       " '무슨': 29,\n",
       " '어디에요': 30,\n",
       " '뭐하고': 31,\n",
       " '시간을': 32,\n",
       " '보내나요': 33,\n",
       " '음악': 34,\n",
       " '장르가': 35,\n",
       " '있나요': 36,\n",
       " \"'인셉션'이에요\": 37,\n",
       " '일하고': 38,\n",
       " '오늘은': 39,\n",
       " '맑아요': 40,\n",
       " '피자에요': 41,\n",
       " '하는': 42,\n",
       " '것을': 43,\n",
       " '파란색이에요': 44,\n",
       " '파리에': 45,\n",
       " '다녀온': 46,\n",
       " '것이에요': 47,\n",
       " '쉬면서': 48,\n",
       " '책을': 49,\n",
       " '읽거나': 50,\n",
       " '친구들과': 51,\n",
       " '만나요': 52,\n",
       " '다양한': 53,\n",
       " '음악을': 54,\n",
       " '즐겨듣습니다': 55,\n",
       " '강아지에요': 56,\n",
       " '전기요금': 57,\n",
       " '이름이': 58,\n",
       " '전기요금이': 59,\n",
       " '계속': 60,\n",
       " '인상되고': 61,\n",
       " '반가워요': 62,\n",
       " '제': 63,\n",
       " '이름은': 64,\n",
       " '챗봇이에요': 65,\n",
       " '너': 66,\n",
       " '뭐니': 67,\n",
       " '어떻게': 68,\n",
       " '지내세요': 69,\n",
       " '어디인가요': 70,\n",
       " '잘': 71,\n",
       " '지내고': 72,\n",
       " '감사합니다': 73,\n",
       " '파리에요': 74,\n",
       " '알려줘': 75,\n",
       " '안녕': 76,\n",
       " '뭐야': 77}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 단어들의 순서 확인하기\n",
    "# - 딕셔너리 타입으로 정의되어 있음(사전의 의미임)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d8bc1",
   "metadata": {},
   "source": [
    "### 훈련 시 사용할 말뭉치 갯수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfac5668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 말뭉치에 포함되지 않은 단어의 경우를 처리하기 위해\n",
    "#   - 토큰화한 결과의 갯수에 1을 더하여 사용\n",
    "\n",
    "### 훈련시 사용할 말뭉치 갯수\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71bca41",
   "metadata": {},
   "source": [
    "### 데이터셋의 텍스트를 말뭉치의 인덱스번호와 매핑하여 숫자화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a635812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "### 텍스트를 말뭉치의 인덱스번호로 숫자화하는 함수 \n",
    "#  - texts_to_sequences(텍스트데이터) 사용\n",
    "\n",
    "### 질문 데이터를 인덱스화 하기\n",
    "questions_sequences = tokenizer.texts_to_sequences(questions)\n",
    "\n",
    "print(len(questions_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83426f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[57, 15],\n",
       " [57, 75],\n",
       " [21],\n",
       " [76],\n",
       " [66, 58, 67],\n",
       " [58, 77],\n",
       " [68, 69],\n",
       " [22, 23, 70],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [1, 16, 17, 18, 19, 3],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [57, 15],\n",
       " [21],\n",
       " [66, 58, 67],\n",
       " [68, 69],\n",
       " [22, 23, 70],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [1, 16, 17, 18, 19, 3],\n",
       " [24, 25],\n",
       " [26, 27, 15],\n",
       " [2, 5, 28],\n",
       " [29, 6, 7],\n",
       " [1, 2, 8, 3],\n",
       " [1, 9, 10, 11, 30],\n",
       " [12, 31, 32, 33],\n",
       " [2, 34, 35, 36],\n",
       " [1, 2, 13, 3],\n",
       " [1, 16, 17, 18, 19, 37]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 인덱스화된 질문데이터\n",
    "# - 2차원 데이터\n",
    "questions_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8cc2e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 3.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 질문에 대한 최대값, 최소값, 중앙값 확인하기\n",
    "# 52개 각각의 문장 내에 단어 갯수 확인하기\n",
    "lengths = np.array([len(x) for x in questions_sequences])\n",
    "\n",
    "np.max(lengths), np.min(lengths), np.median(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34591fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2, 4.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 답변에 대한 최대값, 최소값, 중앙값 확인하기\n",
    "\n",
    "# 답변데이터를 말뭉치사전의 인덱스로 인덱스화 하기\n",
    "answers_sequences = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "# 52개 각각의 문장 내에 단어 갯수 확인하기\n",
    "lengths = np.array([len(x) for x in answers_sequences])\n",
    "\n",
    "np.max(lengths), np.min(lengths), np.median(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352d64e",
   "metadata": {},
   "source": [
    "### 질문 및 답변 데이터 각각에 대해 데이터스케일링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9a51c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57, 15,  0,  0,  0,  0],\n",
       "       [57, 75,  0,  0,  0,  0],\n",
       "       [21,  0,  0,  0,  0,  0],\n",
       "       [76,  0,  0,  0,  0,  0],\n",
       "       [66, 58, 67,  0,  0,  0],\n",
       "       [58, 77,  0,  0,  0,  0],\n",
       "       [68, 69,  0,  0,  0,  0],\n",
       "       [22, 23, 70,  0,  0,  0],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19,  3],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [57, 15,  0,  0,  0,  0],\n",
       "       [21,  0,  0,  0,  0,  0],\n",
       "       [66, 58, 67,  0,  0,  0],\n",
       "       [68, 69,  0,  0,  0,  0],\n",
       "       [22, 23, 70,  0,  0,  0],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19,  3],\n",
       "       [24, 25,  0,  0,  0,  0],\n",
       "       [26, 27, 15,  0,  0,  0],\n",
       "       [ 2,  5, 28,  0,  0,  0],\n",
       "       [29,  6,  7,  0,  0,  0],\n",
       "       [ 1,  2,  8,  3,  0,  0],\n",
       "       [ 1,  9, 10, 11, 30,  0],\n",
       "       [12, 31, 32, 33,  0,  0],\n",
       "       [ 2, 34, 35, 36,  0,  0],\n",
       "       [ 1,  2, 13,  3,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 질문 데이터 데이터스케일링하기(최대 길이로 스케일링)\n",
    "# - 최대 단어 길이로 스케일링하기에, 자르는값 없음. 채우는 값만 존재함\n",
    "# - maxlen 속성은 6, maxlen을 생략하면->전체 데이터의 단어 길이중 최대값을 사용하게됨\n",
    "questions_padded = pad_sequences(questions_sequences, padding=\"post\")\n",
    "questions_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ebb8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59, 60, 61,  4,  0,  0,  0],\n",
       "       [59, 60, 61,  4,  0,  0,  0],\n",
       "       [21, 62,  0,  0,  0,  0,  0],\n",
       "       [21, 62,  0,  0,  0,  0,  0],\n",
       "       [63, 64, 65,  0,  0,  0,  0],\n",
       "       [63, 64, 65,  0,  0,  0,  0],\n",
       "       [20, 71, 72,  4, 73,  0,  0],\n",
       "       [22, 23, 74,  0,  0,  0,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [59, 60, 61,  4,  0,  0,  0],\n",
       "       [21, 62,  0,  0,  0,  0,  0],\n",
       "       [63, 64, 65,  0,  0,  0,  0],\n",
       "       [20, 71, 72,  4, 73,  0,  0],\n",
       "       [22, 23, 74,  0,  0,  0,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37,  0],\n",
       "       [38,  4,  0,  0,  0,  0,  0],\n",
       "       [39, 40,  0,  0,  0,  0,  0],\n",
       "       [14,  2,  5, 41,  0,  0,  0],\n",
       "       [ 6, 42, 43,  7,  0,  0,  0],\n",
       "       [14,  1,  2,  8, 44,  0,  0],\n",
       "       [ 1,  9, 10, 11, 45, 46, 47],\n",
       "       [12, 48, 49, 50, 51, 52,  0],\n",
       "       [20, 53, 54, 55,  0,  0,  0],\n",
       "       [ 1,  2, 13, 56,  0,  0,  0],\n",
       "       [ 1, 16, 17, 18, 19, 37,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 답변 데이터 데이터스케일링하기(최대 길이로 스케일링)\n",
    "answers_padded = pad_sequences(answers_sequences, padding=\"post\")\n",
    "answers_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e5f35",
   "metadata": {},
   "source": [
    "### 훈련 : 테스트 = 8 : 2로 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78455ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 6) (41, 7)\n",
      "(11, 6) (11, 7)\n"
     ]
    }
   ],
   "source": [
    "### 독립변수 = 질문 데이터\n",
    "#   종속변수 = 답변 데이터\n",
    "# 변수명 : questions_train, answers_train, questions_val, answers_val\n",
    "questions_train, questions_val, answers_train, answers_val = train_test_split(\n",
    "    questions_padded, answers_padded, test_size=0.2, random_state=42\n",
    ")\n",
    "print(questions_train.shape, answers_train.shape)\n",
    "print(questions_val.shape, answers_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf53a8",
   "metadata": {},
   "source": [
    "### 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba41806",
   "metadata": {},
   "source": [
    "- 계층 구조 - SimpleRNN 먼저 사용\n",
    "    - 입력계층 : 임베딩계층 사용\n",
    "    - 은닉계층 : SimpleRNN 사용 (질문을 담당하는 계층)\n",
    "    - 은닉계층 : 답변 차원으로 변형하는 계층(RepeatVecotr 계층)\n",
    "    - 은닉계층 : 질문에 대한 답변 처리 계층(SimpleRNN)\n",
    "    - 출력계층 : 질문에 대한 답변을 처리기하기 위한 단어를 조합하는 계층 + 출력계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e66df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               24704     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 7, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 7, 128)            32896     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 7, 78)            10062     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,654\n",
      "Trainable params: 72,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.3636 - accuracy: 0.0000e+00 - val_loss: 4.3222 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.3214 - accuracy: 0.4146 - val_loss: 4.2488 - val_accuracy: 0.4286\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.2397 - accuracy: 0.4181 - val_loss: 4.0440 - val_accuracy: 0.4026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0053 - accuracy: 0.4181 - val_loss: 3.3790 - val_accuracy: 0.4026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2424 - accuracy: 0.4181 - val_loss: 3.2415 - val_accuracy: 0.4026\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1643 - accuracy: 0.4181 - val_loss: 3.2053 - val_accuracy: 0.4026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0138 - accuracy: 0.4181 - val_loss: 2.7858 - val_accuracy: 0.4026\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6156 - accuracy: 0.4181 - val_loss: 2.7646 - val_accuracy: 0.4026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5705 - accuracy: 0.4181 - val_loss: 2.7344 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5266 - accuracy: 0.4181 - val_loss: 2.7119 - val_accuracy: 0.4026\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4849 - accuracy: 0.4181 - val_loss: 2.6741 - val_accuracy: 0.4026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4402 - accuracy: 0.4181 - val_loss: 2.6620 - val_accuracy: 0.4545\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3937 - accuracy: 0.4286 - val_loss: 2.5979 - val_accuracy: 0.4545\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.3472 - accuracy: 0.4286 - val_loss: 2.6631 - val_accuracy: 0.4675\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3278 - accuracy: 0.4390 - val_loss: 2.5937 - val_accuracy: 0.4545\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4002 - accuracy: 0.4286 - val_loss: 2.7480 - val_accuracy: 0.5065\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3778 - accuracy: 0.4843 - val_loss: 2.4577 - val_accuracy: 0.4675\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2472 - accuracy: 0.4390 - val_loss: 2.5167 - val_accuracy: 0.4935\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1359 - accuracy: 0.4739 - val_loss: 2.3445 - val_accuracy: 0.4805\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0405 - accuracy: 0.4634 - val_loss: 2.3774 - val_accuracy: 0.4416\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9660 - accuracy: 0.4495 - val_loss: 2.2287 - val_accuracy: 0.4805\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9265 - accuracy: 0.4634 - val_loss: 2.4955 - val_accuracy: 0.3766\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0099 - accuracy: 0.4739 - val_loss: 2.2155 - val_accuracy: 0.4675\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0292 - accuracy: 0.4669 - val_loss: 2.3319 - val_accuracy: 0.3766\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8698 - accuracy: 0.4983 - val_loss: 2.0128 - val_accuracy: 0.4935\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6738 - accuracy: 0.4878 - val_loss: 1.9822 - val_accuracy: 0.4545\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5857 - accuracy: 0.5052 - val_loss: 1.8456 - val_accuracy: 0.4935\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5098 - accuracy: 0.5157 - val_loss: 1.9214 - val_accuracy: 0.4416\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5147 - accuracy: 0.5436 - val_loss: 1.8356 - val_accuracy: 0.4805\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7427 - accuracy: 0.4808 - val_loss: 2.2202 - val_accuracy: 0.4675\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7693 - accuracy: 0.5610 - val_loss: 1.6918 - val_accuracy: 0.4805\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5101 - accuracy: 0.5052 - val_loss: 1.6741 - val_accuracy: 0.5455\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3465 - accuracy: 0.5958 - val_loss: 1.4542 - val_accuracy: 0.6104\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2367 - accuracy: 0.6063 - val_loss: 1.4683 - val_accuracy: 0.5455\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1897 - accuracy: 0.6341 - val_loss: 1.2649 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1819 - accuracy: 0.6063 - val_loss: 1.5205 - val_accuracy: 0.5325\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1887 - accuracy: 0.6481 - val_loss: 1.1557 - val_accuracy: 0.6623\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0741 - accuracy: 0.6760 - val_loss: 1.1899 - val_accuracy: 0.6234\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0110 - accuracy: 0.6516 - val_loss: 1.2495 - val_accuracy: 0.5844\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3425 - accuracy: 0.6098 - val_loss: 1.9091 - val_accuracy: 0.4026\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "model\n",
    "\n",
    "### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "#    - input_dim : 말뭉치갯수\n",
    "#    - 출력갯수 : 64개\n",
    "#    - input_length : 질문의 특성 갯수\n",
    "model.add(\n",
    "    keras.layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=64,\n",
    "                           input_length=questions_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 추가 : SimpleRNN, 출력:128, 활성화함수:relu\n",
    "# - 질문을 담당하는 계층\n",
    "model.add(\n",
    "    keras.layers.SimpleRNN(units=128, activation=\"relu\")\n",
    ")\n",
    "\n",
    "### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "# - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "model.add(\n",
    "    keras.layers.RepeatVector(answers_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 : SimpleRNN 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "# - return_sequences=True : 훈련결과(단어)를 다음 계층으로 넘겨주기\n",
    "#                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행\n",
    "model.add(\n",
    "    keras.layers.SimpleRNN(units=128, activation=\"relu\", return_sequences=True)\n",
    ")\n",
    "\n",
    "### 단어조합 계층과 출력계층 정의하기\n",
    "# TimeDistributed \n",
    "#  - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "#  - 다음에 올 단어들이 있는지 체크\n",
    "#  - 분류의 개념보다 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "#  - 출력계층을 감싸서 사용\n",
    "# ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환\n",
    "model.add(\n",
    "    keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(units=vocab_size, activation=\"softmax\")\n",
    "    )\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - rmsprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=\"RMSprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.h5\n",
    "save_file = \"./model/best_RNN_chatbot.h5\"\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(save_file, save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수:100회, 배치사이즈:64\n",
    "history = model.fit(questions_train, answers_train, epochs=100, batch_size=64,\n",
    "                    validation_data=(questions_val, answers_val),\n",
    "                    callbacks=[cp_cb, es_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f2952",
   "metadata": {},
   "source": [
    "- 시퀀스 기반의 훈련 성능의 좋음 정도>\n",
    "    - 질문/답변과 같은 시퀀스 기반의 훈련의 경우에는 일반적으로\n",
    "        - loss < 2 이면 학습이 어느정도 잘된 것으로 판단\n",
    "        - loss < 1 이면 매우 잘된 것으로 판단\n",
    "        - 정확도까지 고려하여 판단해야함\n",
    "   \n",
    "    - 시퀀스 기반의 훈련은 데이터량이 성능에 매우 큰 영향을 미침\n",
    "    - 시퀀스 기반의 훈련에서는 tanh 활성화 함수가 성능이 좋게 나오는 경우가 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3ff440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               98816     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 7, 128)            131584    \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,454\n",
      "Trainable params: 245,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.3569 - accuracy: 0.0000e+00 - val_loss: 4.3454 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.3429 - accuracy: 0.4181 - val_loss: 4.3289 - val_accuracy: 0.4026\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.3232 - accuracy: 0.4181 - val_loss: 4.3004 - val_accuracy: 0.4026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.2897 - accuracy: 0.4181 - val_loss: 4.2463 - val_accuracy: 0.4026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.2262 - accuracy: 0.4181 - val_loss: 4.1246 - val_accuracy: 0.4026\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.0829 - accuracy: 0.4181 - val_loss: 3.7763 - val_accuracy: 0.4026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.6669 - accuracy: 0.4181 - val_loss: 2.9366 - val_accuracy: 0.4026\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.7167 - accuracy: 0.4181 - val_loss: 2.9060 - val_accuracy: 0.4026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.8068 - accuracy: 0.4181 - val_loss: 3.2348 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0240 - accuracy: 0.4181 - val_loss: 2.7913 - val_accuracy: 0.4026\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5884 - accuracy: 0.4181 - val_loss: 2.8115 - val_accuracy: 0.4026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.5668 - accuracy: 0.4181 - val_loss: 2.7734 - val_accuracy: 0.4026\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5470 - accuracy: 0.4181 - val_loss: 2.7844 - val_accuracy: 0.4026\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5299 - accuracy: 0.4181 - val_loss: 2.7558 - val_accuracy: 0.4026\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.5132 - accuracy: 0.4181 - val_loss: 2.7675 - val_accuracy: 0.4026\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4979 - accuracy: 0.4181 - val_loss: 2.7380 - val_accuracy: 0.4026\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4828 - accuracy: 0.4181 - val_loss: 2.7629 - val_accuracy: 0.4026\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4716 - accuracy: 0.4181 - val_loss: 2.7224 - val_accuracy: 0.4026\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4652 - accuracy: 0.4181 - val_loss: 2.7981 - val_accuracy: 0.4026\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4825 - accuracy: 0.4181 - val_loss: 2.7269 - val_accuracy: 0.4026\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4985 - accuracy: 0.4181 - val_loss: 2.8789 - val_accuracy: 0.4026\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "model\n",
    "\n",
    "### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "#    - input_dim : 말뭉치갯수\n",
    "#    - 출력갯수 : 64개\n",
    "#    - input_length : 질문의 특성 갯수\n",
    "model.add(\n",
    "    keras.layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=64,\n",
    "                           input_length=questions_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 추가 : LSTM, 출력:128, 활성화함수:relu\n",
    "# - 질문을 담당하는 계층\n",
    "model.add(\n",
    "    keras.layers.LSTM(units=128, activation=\"relu\")\n",
    ")\n",
    "\n",
    "### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "# - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "model.add(\n",
    "    keras.layers.RepeatVector(answers_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 : LSTM 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "# - return_sequences=True : 훈련결과(단어)를 다음 계층으로 넘겨주기\n",
    "#                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행\n",
    "model.add(\n",
    "    keras.layers.LSTM(units=128, activation=\"relu\", return_sequences=True)\n",
    ")\n",
    "\n",
    "### 단어조합 계층과 출력계층 정의하기\n",
    "# TimeDistributed \n",
    "#  - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "#  - 다음에 올 단어들이 있는지 체크\n",
    "#  - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "#  - 출력계층을 감싸서 사용\n",
    "# ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환\n",
    "model.add(\n",
    "    keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(units=vocab_size, activation=\"softmax\")\n",
    "    )\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - rmsprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=\"RMSprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.h5\n",
    "save_file = \"./model/best_RNN_chatbot.h5\"\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(save_file, save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수:100회, 배치사이즈:64\n",
    "history = model.fit(questions_train, answers_train, epochs=100, batch_size=64,\n",
    "                    validation_data=(questions_val, answers_val),\n",
    "                    callbacks=[cp_cb, es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f893c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               74496     \n",
      "                                                                 \n",
      " repeat_vector_2 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 7, 128)            99072     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,622\n",
      "Trainable params: 188,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.3612 - accuracy: 0.0000e+00 - val_loss: 4.3400 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.3377 - accuracy: 0.4181 - val_loss: 4.3149 - val_accuracy: 0.4026\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.3094 - accuracy: 0.4181 - val_loss: 4.2760 - val_accuracy: 0.4026\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.2651 - accuracy: 0.4181 - val_loss: 4.2112 - val_accuracy: 0.4026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1905 - accuracy: 0.4181 - val_loss: 4.0858 - val_accuracy: 0.4026\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.0432 - accuracy: 0.4181 - val_loss: 3.8359 - val_accuracy: 0.4026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.7481 - accuracy: 0.4181 - val_loss: 3.2947 - val_accuracy: 0.4026\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1082 - accuracy: 0.4181 - val_loss: 3.0374 - val_accuracy: 0.4026\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.8841 - accuracy: 0.4181 - val_loss: 3.1721 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9601 - accuracy: 0.4181 - val_loss: 2.8609 - val_accuracy: 0.4026\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.6446 - accuracy: 0.4181 - val_loss: 2.8623 - val_accuracy: 0.4026\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6210 - accuracy: 0.4181 - val_loss: 2.8353 - val_accuracy: 0.4026\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5990 - accuracy: 0.4181 - val_loss: 2.8412 - val_accuracy: 0.4026\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.5799 - accuracy: 0.4181 - val_loss: 2.8129 - val_accuracy: 0.4026\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5614 - accuracy: 0.4181 - val_loss: 2.8302 - val_accuracy: 0.4026\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5472 - accuracy: 0.4181 - val_loss: 2.7938 - val_accuracy: 0.4026\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5374 - accuracy: 0.4181 - val_loss: 2.8450 - val_accuracy: 0.4026\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5400 - accuracy: 0.4181 - val_loss: 2.7885 - val_accuracy: 0.4026\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5461 - accuracy: 0.4181 - val_loss: 2.8801 - val_accuracy: 0.4026\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5639 - accuracy: 0.4181 - val_loss: 2.7716 - val_accuracy: 0.4026\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.5254 - accuracy: 0.4181 - val_loss: 2.8387 - val_accuracy: 0.4026\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5078 - accuracy: 0.4181 - val_loss: 2.7426 - val_accuracy: 0.4026\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4631 - accuracy: 0.4181 - val_loss: 2.7877 - val_accuracy: 0.4026\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4421 - accuracy: 0.4181 - val_loss: 2.7252 - val_accuracy: 0.4026\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4170 - accuracy: 0.4181 - val_loss: 2.7621 - val_accuracy: 0.4026\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4013 - accuracy: 0.4181 - val_loss: 2.7100 - val_accuracy: 0.4026\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.3838 - accuracy: 0.4181 - val_loss: 2.7523 - val_accuracy: 0.4026\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.3732 - accuracy: 0.4321 - val_loss: 2.6941 - val_accuracy: 0.4156\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3612 - accuracy: 0.4425 - val_loss: 2.7612 - val_accuracy: 0.4156\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3632 - accuracy: 0.4425 - val_loss: 2.6813 - val_accuracy: 0.4156\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3572 - accuracy: 0.4425 - val_loss: 2.7817 - val_accuracy: 0.4156\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.3726 - accuracy: 0.4425 - val_loss: 2.6616 - val_accuracy: 0.4156\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3377 - accuracy: 0.4425 - val_loss: 2.7568 - val_accuracy: 0.4286\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3347 - accuracy: 0.4530 - val_loss: 2.6361 - val_accuracy: 0.4156\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2845 - accuracy: 0.4425 - val_loss: 2.7098 - val_accuracy: 0.4286\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2699 - accuracy: 0.4530 - val_loss: 2.6124 - val_accuracy: 0.4286\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2344 - accuracy: 0.4530 - val_loss: 2.6831 - val_accuracy: 0.4286\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2247 - accuracy: 0.4530 - val_loss: 2.5887 - val_accuracy: 0.4286\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2025 - accuracy: 0.4530 - val_loss: 2.6870 - val_accuracy: 0.4156\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2104 - accuracy: 0.4530 - val_loss: 2.5658 - val_accuracy: 0.4286\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1911 - accuracy: 0.4530 - val_loss: 2.7020 - val_accuracy: 0.3766\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2183 - accuracy: 0.4425 - val_loss: 2.5412 - val_accuracy: 0.4416\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1691 - accuracy: 0.4774 - val_loss: 2.6722 - val_accuracy: 0.3766\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1759 - accuracy: 0.4425 - val_loss: 2.5074 - val_accuracy: 0.4416\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.1085 - accuracy: 0.4774 - val_loss: 2.6157 - val_accuracy: 0.3766\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1033 - accuracy: 0.4425 - val_loss: 2.4742 - val_accuracy: 0.4416\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0599 - accuracy: 0.4774 - val_loss: 2.5973 - val_accuracy: 0.3766\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.0690 - accuracy: 0.4425 - val_loss: 2.4407 - val_accuracy: 0.4416\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0428 - accuracy: 0.4774 - val_loss: 2.6104 - val_accuracy: 0.3766\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0777 - accuracy: 0.4425 - val_loss: 2.4100 - val_accuracy: 0.4416\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.0338 - accuracy: 0.4774 - val_loss: 2.5906 - val_accuracy: 0.3896\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0544 - accuracy: 0.4530 - val_loss: 2.3647 - val_accuracy: 0.4416\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9719 - accuracy: 0.4774 - val_loss: 2.5190 - val_accuracy: 0.3896\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9728 - accuracy: 0.4564 - val_loss: 2.3200 - val_accuracy: 0.4416\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9243 - accuracy: 0.4808 - val_loss: 2.4937 - val_accuracy: 0.4026\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9407 - accuracy: 0.4634 - val_loss: 2.2810 - val_accuracy: 0.4545\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9185 - accuracy: 0.4913 - val_loss: 2.4999 - val_accuracy: 0.4286\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9483 - accuracy: 0.5157 - val_loss: 2.2553 - val_accuracy: 0.4545\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9050 - accuracy: 0.4774 - val_loss: 2.4663 - val_accuracy: 0.4026\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.9178 - accuracy: 0.5052 - val_loss: 2.2147 - val_accuracy: 0.4675\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8367 - accuracy: 0.4913 - val_loss: 2.3765 - val_accuracy: 0.4156\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8263 - accuracy: 0.5052 - val_loss: 2.1884 - val_accuracy: 0.4675\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7831 - accuracy: 0.4913 - val_loss: 2.3640 - val_accuracy: 0.4026\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8021 - accuracy: 0.5226 - val_loss: 2.1750 - val_accuracy: 0.4675\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7964 - accuracy: 0.4913 - val_loss: 2.3915 - val_accuracy: 0.4026\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8295 - accuracy: 0.5122 - val_loss: 2.1353 - val_accuracy: 0.4675\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7870 - accuracy: 0.4913 - val_loss: 2.3142 - val_accuracy: 0.4026\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7674 - accuracy: 0.5331 - val_loss: 2.1100 - val_accuracy: 0.4416\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6975 - accuracy: 0.4913 - val_loss: 2.2403 - val_accuracy: 0.4026\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6913 - accuracy: 0.5331 - val_loss: 2.1153 - val_accuracy: 0.4416\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6876 - accuracy: 0.4913 - val_loss: 2.2676 - val_accuracy: 0.4026\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "model\n",
    "\n",
    "### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "#    - input_dim : 말뭉치갯수\n",
    "#    - 출력갯수 : 64개\n",
    "#    - input_length : 질문의 특성 갯수\n",
    "model.add(\n",
    "    keras.layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=64,\n",
    "                           input_length=questions_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 추가 : GRU, 출력:128, 활성화함수:relu\n",
    "# - 질문을 담당하는 계층\n",
    "model.add(\n",
    "    keras.layers.GRU(units=128, activation=\"relu\")\n",
    ")\n",
    "\n",
    "### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "# - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "model.add(\n",
    "    keras.layers.RepeatVector(answers_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 : GRU 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "# - return_sequences=True : 훈련결과(단어)를 다음 계층으로 넘겨주기\n",
    "#                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행\n",
    "model.add(\n",
    "    keras.layers.GRU(units=128, activation=\"relu\", return_sequences=True)\n",
    ")\n",
    "\n",
    "### 단어조합 계층과 출력계층 정의하기\n",
    "# TimeDistributed \n",
    "#  - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "#  - 다음에 올 단어들이 있는지 체크\n",
    "#  - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "#  - 출력계층을 감싸서 사용\n",
    "# ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환\n",
    "model.add(\n",
    "    keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(units=vocab_size, activation=\"softmax\")\n",
    "    )\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - rmsprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=\"RMSprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.h5\n",
    "save_file = \"./model/best_RNN_chatbot.h5\"\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(save_file, save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수:100회, 배치사이즈:64\n",
    "history = model.fit(questions_train, answers_train, epochs=100, batch_size=64,\n",
    "                    validation_data=(questions_val, answers_val),\n",
    "                    callbacks=[cp_cb, es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ce4c204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               74496     \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 7, 128)            99072     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,622\n",
      "Trainable params: 188,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.3583 - accuracy: 0.0000e+00 - val_loss: 4.3337 - val_accuracy: 0.4026\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.3302 - accuracy: 0.4181 - val_loss: 4.3009 - val_accuracy: 0.4026\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.2931 - accuracy: 0.4181 - val_loss: 4.2492 - val_accuracy: 0.4026\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.2333 - accuracy: 0.4181 - val_loss: 4.1609 - val_accuracy: 0.4026\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1299 - accuracy: 0.4181 - val_loss: 3.9928 - val_accuracy: 0.4026\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.9320 - accuracy: 0.4181 - val_loss: 3.6370 - val_accuracy: 0.4026\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.5115 - accuracy: 0.4181 - val_loss: 2.9637 - val_accuracy: 0.4026\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7415 - accuracy: 0.4181 - val_loss: 3.1111 - val_accuracy: 0.4026\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9669 - accuracy: 0.4181 - val_loss: 3.1373 - val_accuracy: 0.4026\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9140 - accuracy: 0.4181 - val_loss: 2.8402 - val_accuracy: 0.4026\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.6098 - accuracy: 0.4181 - val_loss: 2.8388 - val_accuracy: 0.4026\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.5916 - accuracy: 0.4181 - val_loss: 2.8257 - val_accuracy: 0.4026\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5747 - accuracy: 0.4181 - val_loss: 2.8221 - val_accuracy: 0.4026\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5585 - accuracy: 0.4181 - val_loss: 2.8121 - val_accuracy: 0.4026\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5425 - accuracy: 0.4181 - val_loss: 2.8086 - val_accuracy: 0.4026\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.5269 - accuracy: 0.4181 - val_loss: 2.7990 - val_accuracy: 0.4026\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5113 - accuracy: 0.4181 - val_loss: 2.7964 - val_accuracy: 0.4026\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4958 - accuracy: 0.4181 - val_loss: 2.7853 - val_accuracy: 0.4026\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4804 - accuracy: 0.4181 - val_loss: 2.7863 - val_accuracy: 0.4026\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4653 - accuracy: 0.4181 - val_loss: 2.7690 - val_accuracy: 0.4026\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4512 - accuracy: 0.4181 - val_loss: 2.7890 - val_accuracy: 0.4026\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4421 - accuracy: 0.4181 - val_loss: 2.7556 - val_accuracy: 0.4026\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4511 - accuracy: 0.4181 - val_loss: 2.8697 - val_accuracy: 0.4026\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5095 - accuracy: 0.4181 - val_loss: 2.7893 - val_accuracy: 0.4026\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5437 - accuracy: 0.4181 - val_loss: 2.9029 - val_accuracy: 0.4026\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.5485 - accuracy: 0.4181 - val_loss: 2.7239 - val_accuracy: 0.4026\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4153 - accuracy: 0.4181 - val_loss: 2.7653 - val_accuracy: 0.4026\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3879 - accuracy: 0.4181 - val_loss: 2.7152 - val_accuracy: 0.4026\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.3644 - accuracy: 0.4181 - val_loss: 2.7397 - val_accuracy: 0.4026\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3504 - accuracy: 0.4181 - val_loss: 2.7090 - val_accuracy: 0.4026\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3368 - accuracy: 0.4181 - val_loss: 2.7326 - val_accuracy: 0.4026\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.3259 - accuracy: 0.4181 - val_loss: 2.6973 - val_accuracy: 0.4026\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.3164 - accuracy: 0.4181 - val_loss: 2.7431 - val_accuracy: 0.4026\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3159 - accuracy: 0.4181 - val_loss: 2.6864 - val_accuracy: 0.4026\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3282 - accuracy: 0.4181 - val_loss: 2.8130 - val_accuracy: 0.4286\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3830 - accuracy: 0.4286 - val_loss: 2.6867 - val_accuracy: 0.4026\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3816 - accuracy: 0.4216 - val_loss: 2.8196 - val_accuracy: 0.4675\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3988 - accuracy: 0.4390 - val_loss: 2.6480 - val_accuracy: 0.4675\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2886 - accuracy: 0.4390 - val_loss: 2.7104 - val_accuracy: 0.4675\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2664 - accuracy: 0.4390 - val_loss: 2.6372 - val_accuracy: 0.4675\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2360 - accuracy: 0.4390 - val_loss: 2.6845 - val_accuracy: 0.4805\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2227 - accuracy: 0.4634 - val_loss: 2.6226 - val_accuracy: 0.4675\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2080 - accuracy: 0.4390 - val_loss: 2.6925 - val_accuracy: 0.4805\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2101 - accuracy: 0.4634 - val_loss: 2.6028 - val_accuracy: 0.4805\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2216 - accuracy: 0.4634 - val_loss: 2.7581 - val_accuracy: 0.4286\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.2814 - accuracy: 0.4460 - val_loss: 2.5869 - val_accuracy: 0.4805\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2599 - accuracy: 0.4634 - val_loss: 2.7432 - val_accuracy: 0.4286\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.2753 - accuracy: 0.4460 - val_loss: 2.5527 - val_accuracy: 0.4805\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1639 - accuracy: 0.4634 - val_loss: 2.6346 - val_accuracy: 0.4416\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1434 - accuracy: 0.4495 - val_loss: 2.5340 - val_accuracy: 0.4805\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1057 - accuracy: 0.4634 - val_loss: 2.6063 - val_accuracy: 0.4416\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0971 - accuracy: 0.4564 - val_loss: 2.5055 - val_accuracy: 0.4805\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0862 - accuracy: 0.4634 - val_loss: 2.6406 - val_accuracy: 0.4286\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1228 - accuracy: 0.4460 - val_loss: 2.4862 - val_accuracy: 0.4935\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1525 - accuracy: 0.4739 - val_loss: 2.7094 - val_accuracy: 0.3766\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2186 - accuracy: 0.4460 - val_loss: 2.4472 - val_accuracy: 0.4935\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.0958 - accuracy: 0.4739 - val_loss: 2.5813 - val_accuracy: 0.4286\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0727 - accuracy: 0.4460 - val_loss: 2.4136 - val_accuracy: 0.4805\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.9999 - accuracy: 0.4739 - val_loss: 2.5161 - val_accuracy: 0.4286\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9892 - accuracy: 0.4669 - val_loss: 2.3755 - val_accuracy: 0.4805\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9690 - accuracy: 0.4739 - val_loss: 2.5340 - val_accuracy: 0.4156\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0008 - accuracy: 0.4808 - val_loss: 2.3446 - val_accuracy: 0.4935\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0350 - accuracy: 0.4739 - val_loss: 2.5955 - val_accuracy: 0.3896\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.0851 - accuracy: 0.4530 - val_loss: 2.3036 - val_accuracy: 0.5065\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9916 - accuracy: 0.4843 - val_loss: 2.4703 - val_accuracy: 0.4416\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9526 - accuracy: 0.5017 - val_loss: 2.2548 - val_accuracy: 0.4675\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8817 - accuracy: 0.4808 - val_loss: 2.3985 - val_accuracy: 0.4545\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8675 - accuracy: 0.5122 - val_loss: 2.2153 - val_accuracy: 0.4675\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8610 - accuracy: 0.4808 - val_loss: 2.4285 - val_accuracy: 0.4156\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.8934 - accuracy: 0.5226 - val_loss: 2.2118 - val_accuracy: 0.4675\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9370 - accuracy: 0.4808 - val_loss: 2.4232 - val_accuracy: 0.4156\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9337 - accuracy: 0.5017 - val_loss: 2.1660 - val_accuracy: 0.4675\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8207 - accuracy: 0.4808 - val_loss: 2.2817 - val_accuracy: 0.4675\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.7716 - accuracy: 0.5296 - val_loss: 2.1403 - val_accuracy: 0.4805\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.7291 - accuracy: 0.4913 - val_loss: 2.2516 - val_accuracy: 0.4675\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7347 - accuracy: 0.5366 - val_loss: 2.1786 - val_accuracy: 0.4805\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7554 - accuracy: 0.4983 - val_loss: 2.3375 - val_accuracy: 0.4286\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8187 - accuracy: 0.4774 - val_loss: 2.0658 - val_accuracy: 0.5065\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8316 - accuracy: 0.4983 - val_loss: 2.3499 - val_accuracy: 0.4286\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.7998 - accuracy: 0.4983 - val_loss: 2.0276 - val_accuracy: 0.4935\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7758 - accuracy: 0.5017 - val_loss: 2.1922 - val_accuracy: 0.4805\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6404 - accuracy: 0.5679 - val_loss: 2.0671 - val_accuracy: 0.4805\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5714 - accuracy: 0.5192 - val_loss: 2.0636 - val_accuracy: 0.5325\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5352 - accuracy: 0.5679 - val_loss: 2.0060 - val_accuracy: 0.5065\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5264 - accuracy: 0.5192 - val_loss: 2.0942 - val_accuracy: 0.4935\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5746 - accuracy: 0.5505 - val_loss: 2.1076 - val_accuracy: 0.5065\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.7498 - accuracy: 0.5192 - val_loss: 2.6078 - val_accuracy: 0.3896\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0423 - accuracy: 0.4007 - val_loss: 1.8516 - val_accuracy: 0.5455\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9129 - accuracy: 0.5331 - val_loss: 1.9748 - val_accuracy: 0.5065\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5592 - accuracy: 0.5714 - val_loss: 1.8414 - val_accuracy: 0.5065\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4456 - accuracy: 0.5505 - val_loss: 1.8146 - val_accuracy: 0.5325\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3985 - accuracy: 0.5679 - val_loss: 1.7996 - val_accuracy: 0.5065\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3583 - accuracy: 0.5714 - val_loss: 1.7681 - val_accuracy: 0.5325\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3221 - accuracy: 0.5749 - val_loss: 1.8381 - val_accuracy: 0.4935\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3202 - accuracy: 0.5679 - val_loss: 1.8367 - val_accuracy: 0.5065\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3633 - accuracy: 0.5610 - val_loss: 1.9268 - val_accuracy: 0.4805\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5542 - accuracy: 0.5122 - val_loss: 2.3765 - val_accuracy: 0.3636\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9632 - accuracy: 0.4042 - val_loss: 1.9087 - val_accuracy: 0.5065\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0920 - accuracy: 0.5157 - val_loss: 1.9642 - val_accuracy: 0.4286\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5647 - accuracy: 0.4913 - val_loss: 1.6539 - val_accuracy: 0.4935\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3473 - accuracy: 0.5505 - val_loss: 1.6697 - val_accuracy: 0.4935\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2794 - accuracy: 0.5854 - val_loss: 1.6358 - val_accuracy: 0.5195\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2385 - accuracy: 0.5854 - val_loss: 1.6216 - val_accuracy: 0.4935\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2032 - accuracy: 0.5993 - val_loss: 1.5970 - val_accuracy: 0.5195\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1681 - accuracy: 0.6098 - val_loss: 1.5995 - val_accuracy: 0.5455\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1345 - accuracy: 0.6307 - val_loss: 1.5711 - val_accuracy: 0.5584\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1425 - accuracy: 0.6272 - val_loss: 2.1786 - val_accuracy: 0.4805\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3921 - accuracy: 0.5366 - val_loss: 1.8108 - val_accuracy: 0.5584\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5628 - accuracy: 0.5679 - val_loss: 2.0278 - val_accuracy: 0.4805\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4764 - accuracy: 0.5610 - val_loss: 1.4646 - val_accuracy: 0.5714\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3920 - accuracy: 0.5401 - val_loss: 1.8739 - val_accuracy: 0.4935\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5277 - accuracy: 0.5052 - val_loss: 1.5800 - val_accuracy: 0.5455\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6425 - accuracy: 0.5470 - val_loss: 1.7842 - val_accuracy: 0.4935\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4288 - accuracy: 0.5261 - val_loss: 1.3292 - val_accuracy: 0.5714\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2274 - accuracy: 0.5958 - val_loss: 1.4476 - val_accuracy: 0.5584\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1153 - accuracy: 0.6028 - val_loss: 1.3468 - val_accuracy: 0.5584\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0477 - accuracy: 0.6481 - val_loss: 1.3431 - val_accuracy: 0.5714\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0095 - accuracy: 0.6376 - val_loss: 1.3022 - val_accuracy: 0.5584\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9840 - accuracy: 0.6551 - val_loss: 1.3568 - val_accuracy: 0.6234\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9696 - accuracy: 0.6620 - val_loss: 1.3375 - val_accuracy: 0.5974\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9898 - accuracy: 0.6516 - val_loss: 1.3116 - val_accuracy: 0.6234\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0696 - accuracy: 0.6376 - val_loss: 1.3623 - val_accuracy: 0.5974\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0526 - accuracy: 0.6132 - val_loss: 1.2586 - val_accuracy: 0.6753\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0543 - accuracy: 0.6376 - val_loss: 1.9510 - val_accuracy: 0.5714\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3536 - accuracy: 0.5679 - val_loss: 3.3592 - val_accuracy: 0.4416\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.8615 - accuracy: 0.3693 - val_loss: 1.3735 - val_accuracy: 0.6104\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9837 - accuracy: 0.5401 - val_loss: 1.3684 - val_accuracy: 0.6104\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1862 - accuracy: 0.6063 - val_loss: 1.1337 - val_accuracy: 0.6883\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0209 - accuracy: 0.6655 - val_loss: 1.0913 - val_accuracy: 0.6753\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9772 - accuracy: 0.6864 - val_loss: 1.0710 - val_accuracy: 0.7013\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9436 - accuracy: 0.6969 - val_loss: 1.0475 - val_accuracy: 0.7013\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9128 - accuracy: 0.6899 - val_loss: 1.0286 - val_accuracy: 0.6753\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8828 - accuracy: 0.7108 - val_loss: 1.0083 - val_accuracy: 0.6753\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8525 - accuracy: 0.7178 - val_loss: 0.9882 - val_accuracy: 0.6753\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8219 - accuracy: 0.7352 - val_loss: 0.9697 - val_accuracy: 0.6623\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7910 - accuracy: 0.7247 - val_loss: 0.9649 - val_accuracy: 0.6364\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7610 - accuracy: 0.7282 - val_loss: 0.9262 - val_accuracy: 0.7013\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7506 - accuracy: 0.7352 - val_loss: 1.3166 - val_accuracy: 0.6494\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8861 - accuracy: 0.6864 - val_loss: 1.1011 - val_accuracy: 0.6753\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1178 - accuracy: 0.6655 - val_loss: 2.3197 - val_accuracy: 0.5714\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5342 - accuracy: 0.5714 - val_loss: 2.8490 - val_accuracy: 0.4805\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4236 - accuracy: 0.4181 - val_loss: 1.4798 - val_accuracy: 0.5714\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.9375 - accuracy: 0.5610 - val_loss: 1.3425 - val_accuracy: 0.5974\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1828 - accuracy: 0.6063 - val_loss: 1.0165 - val_accuracy: 0.7143\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9468 - accuracy: 0.6829 - val_loss: 0.9260 - val_accuracy: 0.7532\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8826 - accuracy: 0.6864 - val_loss: 0.8785 - val_accuracy: 0.7662\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8410 - accuracy: 0.6899 - val_loss: 0.8699 - val_accuracy: 0.7273\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8071 - accuracy: 0.7178 - val_loss: 0.8545 - val_accuracy: 0.7273\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7782 - accuracy: 0.7247 - val_loss: 0.8498 - val_accuracy: 0.7403\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7520 - accuracy: 0.7631 - val_loss: 0.8321 - val_accuracy: 0.7403\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7274 - accuracy: 0.7631 - val_loss: 0.8532 - val_accuracy: 0.7143\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7054 - accuracy: 0.7909 - val_loss: 0.8166 - val_accuracy: 0.7403\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6959 - accuracy: 0.7561 - val_loss: 0.9939 - val_accuracy: 0.7273\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7130 - accuracy: 0.7631 - val_loss: 0.8498 - val_accuracy: 0.8052\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7313 - accuracy: 0.7456 - val_loss: 1.0414 - val_accuracy: 0.7662\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7939 - accuracy: 0.7387 - val_loss: 1.1353 - val_accuracy: 0.7403\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9882 - accuracy: 0.6132 - val_loss: 4.1574 - val_accuracy: 0.4286\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5208 - accuracy: 0.3902 - val_loss: 1.8104 - val_accuracy: 0.6104\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1302 - accuracy: 0.5610 - val_loss: 1.5380 - val_accuracy: 0.6883\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1994 - accuracy: 0.6307 - val_loss: 1.1629 - val_accuracy: 0.7013\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8930 - accuracy: 0.6829 - val_loss: 0.9333 - val_accuracy: 0.7143\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8030 - accuracy: 0.7247 - val_loss: 0.8415 - val_accuracy: 0.7662\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7514 - accuracy: 0.7352 - val_loss: 0.8200 - val_accuracy: 0.7662\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7209 - accuracy: 0.7700 - val_loss: 0.8089 - val_accuracy: 0.7792\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6990 - accuracy: 0.7944 - val_loss: 0.8009 - val_accuracy: 0.7662\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6791 - accuracy: 0.7875 - val_loss: 0.7945 - val_accuracy: 0.7403\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6602 - accuracy: 0.7805 - val_loss: 0.7911 - val_accuracy: 0.7662\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6416 - accuracy: 0.7875 - val_loss: 0.7889 - val_accuracy: 0.7532\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6242 - accuracy: 0.7805 - val_loss: 0.7764 - val_accuracy: 0.7792\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6131 - accuracy: 0.7805 - val_loss: 0.8267 - val_accuracy: 0.7273\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6458 - accuracy: 0.7596 - val_loss: 0.8186 - val_accuracy: 0.7273\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7315 - accuracy: 0.7282 - val_loss: 1.2899 - val_accuracy: 0.7013\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9465 - accuracy: 0.6794 - val_loss: 1.5523 - val_accuracy: 0.7143\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0677 - accuracy: 0.6307 - val_loss: 1.8016 - val_accuracy: 0.6234\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.7292 - accuracy: 0.6028 - val_loss: 2.7748 - val_accuracy: 0.4805\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2504 - accuracy: 0.4321 - val_loss: 1.1797 - val_accuracy: 0.6234\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.3522 - accuracy: 0.6063 - val_loss: 0.9676 - val_accuracy: 0.7403\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8239 - accuracy: 0.7178 - val_loss: 1.0181 - val_accuracy: 0.7532\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7898 - accuracy: 0.7491 - val_loss: 0.7883 - val_accuracy: 0.7792\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6885 - accuracy: 0.7909 - val_loss: 0.7459 - val_accuracy: 0.7792\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6575 - accuracy: 0.7735 - val_loss: 0.7551 - val_accuracy: 0.7662\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6302 - accuracy: 0.8014 - val_loss: 0.7198 - val_accuracy: 0.7922\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6085 - accuracy: 0.7805 - val_loss: 0.7573 - val_accuracy: 0.7662\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5934 - accuracy: 0.8084 - val_loss: 0.7088 - val_accuracy: 0.7922\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5912 - accuracy: 0.7631 - val_loss: 0.9053 - val_accuracy: 0.7662\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6365 - accuracy: 0.7805 - val_loss: 0.6660 - val_accuracy: 0.8182\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6611 - accuracy: 0.7247 - val_loss: 1.0338 - val_accuracy: 0.7662\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7254 - accuracy: 0.7491 - val_loss: 0.6530 - val_accuracy: 0.7532\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8823 - accuracy: 0.6725 - val_loss: 1.6015 - val_accuracy: 0.6623\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3351 - accuracy: 0.5505 - val_loss: 2.4946 - val_accuracy: 0.5974\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.0854 - accuracy: 0.5366 - val_loss: 2.6047 - val_accuracy: 0.5195\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8310 - accuracy: 0.5087 - val_loss: 1.1033 - val_accuracy: 0.6753\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9590 - accuracy: 0.6725 - val_loss: 1.0322 - val_accuracy: 0.7143\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7628 - accuracy: 0.7317 - val_loss: 0.7555 - val_accuracy: 0.7662\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6280 - accuracy: 0.7909 - val_loss: 0.7166 - val_accuracy: 0.7922\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5938 - accuracy: 0.8118 - val_loss: 0.7156 - val_accuracy: 0.8052\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5729 - accuracy: 0.8223 - val_loss: 0.7050 - val_accuracy: 0.8052\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5556 - accuracy: 0.8362 - val_loss: 0.7189 - val_accuracy: 0.7662\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5394 - accuracy: 0.8467 - val_loss: 0.7042 - val_accuracy: 0.8182\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5270 - accuracy: 0.8537 - val_loss: 0.7907 - val_accuracy: 0.7922\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5241 - accuracy: 0.8537 - val_loss: 0.7165 - val_accuracy: 0.8182\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5309 - accuracy: 0.8362 - val_loss: 0.9539 - val_accuracy: 0.7792\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5760 - accuracy: 0.7666 - val_loss: 0.8395 - val_accuracy: 0.7532\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6554 - accuracy: 0.7526 - val_loss: 1.3674 - val_accuracy: 0.6623\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8843 - accuracy: 0.7108 - val_loss: 1.3028 - val_accuracy: 0.7143\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9974 - accuracy: 0.5854 - val_loss: 2.9297 - val_accuracy: 0.6623\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.4604 - accuracy: 0.5366 - val_loss: 2.5525 - val_accuracy: 0.5455\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.8523 - accuracy: 0.5087 - val_loss: 0.7083 - val_accuracy: 0.7792\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8829 - accuracy: 0.7178 - val_loss: 0.7947 - val_accuracy: 0.8182\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6876 - accuracy: 0.7979 - val_loss: 1.2722 - val_accuracy: 0.8052\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7644 - accuracy: 0.7700 - val_loss: 1.1540 - val_accuracy: 0.7792\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6918 - accuracy: 0.8153 - val_loss: 1.0712 - val_accuracy: 0.8182\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6503 - accuracy: 0.7979 - val_loss: 1.1254 - val_accuracy: 0.7922\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6300 - accuracy: 0.8537 - val_loss: 1.0924 - val_accuracy: 0.8182\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6165 - accuracy: 0.8223 - val_loss: 1.1744 - val_accuracy: 0.7922\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6138 - accuracy: 0.8328 - val_loss: 1.1106 - val_accuracy: 0.7922\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6278 - accuracy: 0.7875 - val_loss: 1.2942 - val_accuracy: 0.7792\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6522 - accuracy: 0.8223 - val_loss: 1.0566 - val_accuracy: 0.7922\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6928 - accuracy: 0.7561 - val_loss: 1.5270 - val_accuracy: 0.7792\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8373 - accuracy: 0.7038 - val_loss: 1.5413 - val_accuracy: 0.7143\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4075 - accuracy: 0.6132 - val_loss: 2.8814 - val_accuracy: 0.5714\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0746 - accuracy: 0.4460 - val_loss: 1.6767 - val_accuracy: 0.7013\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4690 - accuracy: 0.6551 - val_loss: 1.1245 - val_accuracy: 0.7662\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7592 - accuracy: 0.7422 - val_loss: 1.4342 - val_accuracy: 0.7403\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7971 - accuracy: 0.7770 - val_loss: 0.9073 - val_accuracy: 0.7662\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5864 - accuracy: 0.8049 - val_loss: 1.0518 - val_accuracy: 0.7273\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5934 - accuracy: 0.8258 - val_loss: 0.7799 - val_accuracy: 0.7922\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5301 - accuracy: 0.8362 - val_loss: 0.7015 - val_accuracy: 0.8182\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4823 - accuracy: 0.8467 - val_loss: 0.7226 - val_accuracy: 0.8182\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4661 - accuracy: 0.8467 - val_loss: 0.7360 - val_accuracy: 0.8182\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4706 - accuracy: 0.8537 - val_loss: 0.7686 - val_accuracy: 0.7922\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4701 - accuracy: 0.8746 - val_loss: 0.7438 - val_accuracy: 0.7922\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5241 - accuracy: 0.7944 - val_loss: 0.9818 - val_accuracy: 0.7922\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5900 - accuracy: 0.7735 - val_loss: 0.6966 - val_accuracy: 0.7662\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6722 - accuracy: 0.7213 - val_loss: 1.2386 - val_accuracy: 0.7532\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8401 - accuracy: 0.6760 - val_loss: 1.4610 - val_accuracy: 0.6623\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3672 - accuracy: 0.5993 - val_loss: 2.4381 - val_accuracy: 0.5325\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6912 - accuracy: 0.5017 - val_loss: 0.7922 - val_accuracy: 0.7532\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1220 - accuracy: 0.6620 - val_loss: 1.1034 - val_accuracy: 0.7403\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7181 - accuracy: 0.8258 - val_loss: 0.8918 - val_accuracy: 0.7792\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6345 - accuracy: 0.8118 - val_loss: 0.7955 - val_accuracy: 0.7532\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5198 - accuracy: 0.8606 - val_loss: 0.7062 - val_accuracy: 0.7792\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4805 - accuracy: 0.8641 - val_loss: 0.8354 - val_accuracy: 0.7662\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4693 - accuracy: 0.8815 - val_loss: 0.7023 - val_accuracy: 0.8052\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4658 - accuracy: 0.8606 - val_loss: 0.8603 - val_accuracy: 0.7662\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4535 - accuracy: 0.8746 - val_loss: 0.7146 - val_accuracy: 0.7922\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4402 - accuracy: 0.8537 - val_loss: 0.9066 - val_accuracy: 0.7662\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4436 - accuracy: 0.8537 - val_loss: 0.7555 - val_accuracy: 0.7922\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4510 - accuracy: 0.8641 - val_loss: 0.9064 - val_accuracy: 0.7662\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4363 - accuracy: 0.8537 - val_loss: 0.9787 - val_accuracy: 0.8052\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5818 - accuracy: 0.8258 - val_loss: 1.2835 - val_accuracy: 0.7532\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6680 - accuracy: 0.7735 - val_loss: 1.6788 - val_accuracy: 0.7403\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0786 - accuracy: 0.7003 - val_loss: 1.2040 - val_accuracy: 0.7403\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5052 - accuracy: 0.6760 - val_loss: 1.9123 - val_accuracy: 0.6883\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.8550 - accuracy: 0.5540 - val_loss: 1.9417 - val_accuracy: 0.5974\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5722 - accuracy: 0.6341 - val_loss: 1.3290 - val_accuracy: 0.7532\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7916 - accuracy: 0.7631 - val_loss: 1.2298 - val_accuracy: 0.7403\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6552 - accuracy: 0.8397 - val_loss: 1.8202 - val_accuracy: 0.6883\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7494 - accuracy: 0.8397 - val_loss: 1.2226 - val_accuracy: 0.7403\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6071 - accuracy: 0.8606 - val_loss: 1.1013 - val_accuracy: 0.7662\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5375 - accuracy: 0.8711 - val_loss: 0.7218 - val_accuracy: 0.8182\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4233 - accuracy: 0.8746 - val_loss: 0.6963 - val_accuracy: 0.8182\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4043 - accuracy: 0.8885 - val_loss: 0.7287 - val_accuracy: 0.8182\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3902 - accuracy: 0.9164 - val_loss: 0.7213 - val_accuracy: 0.8182\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3790 - accuracy: 0.8815 - val_loss: 0.7671 - val_accuracy: 0.8442\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3746 - accuracy: 0.8815 - val_loss: 0.7451 - val_accuracy: 0.8182\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3923 - accuracy: 0.8606 - val_loss: 0.9204 - val_accuracy: 0.8182\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4274 - accuracy: 0.8502 - val_loss: 0.6543 - val_accuracy: 0.8182\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5381 - accuracy: 0.7735 - val_loss: 1.4458 - val_accuracy: 0.7403\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0338 - accuracy: 0.7073 - val_loss: 1.3109 - val_accuracy: 0.7013\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6265 - accuracy: 0.6028 - val_loss: 2.3570 - val_accuracy: 0.6234\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7884 - accuracy: 0.4983 - val_loss: 1.9272 - val_accuracy: 0.6494\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1035 - accuracy: 0.6829 - val_loss: 0.9015 - val_accuracy: 0.7922\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4964 - accuracy: 0.8362 - val_loss: 0.7270 - val_accuracy: 0.8182\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4315 - accuracy: 0.8571 - val_loss: 0.7306 - val_accuracy: 0.8182\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4076 - accuracy: 0.8815 - val_loss: 0.7083 - val_accuracy: 0.8182\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3907 - accuracy: 0.8885 - val_loss: 0.7118 - val_accuracy: 0.8182\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3779 - accuracy: 0.8885 - val_loss: 0.7051 - val_accuracy: 0.8182\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3676 - accuracy: 0.8885 - val_loss: 0.7288 - val_accuracy: 0.8442\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3611 - accuracy: 0.8815 - val_loss: 0.7266 - val_accuracy: 0.8442\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3636 - accuracy: 0.8815 - val_loss: 0.8064 - val_accuracy: 0.8182\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3696 - accuracy: 0.8746 - val_loss: 0.7540 - val_accuracy: 0.8442\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3831 - accuracy: 0.8746 - val_loss: 0.9018 - val_accuracy: 0.8182\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3905 - accuracy: 0.8537 - val_loss: 0.7384 - val_accuracy: 0.7922\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3897 - accuracy: 0.8537 - val_loss: 0.9873 - val_accuracy: 0.8182\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4266 - accuracy: 0.8537 - val_loss: 0.5829 - val_accuracy: 0.8442\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5562 - accuracy: 0.7840 - val_loss: 1.4645 - val_accuracy: 0.7403\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9522 - accuracy: 0.7108 - val_loss: 0.9379 - val_accuracy: 0.7792\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.5089 - accuracy: 0.6167 - val_loss: 1.6592 - val_accuracy: 0.6883\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1263 - accuracy: 0.6132 - val_loss: 2.0207 - val_accuracy: 0.6494\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0827 - accuracy: 0.6864 - val_loss: 1.3895 - val_accuracy: 0.7922\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6781 - accuracy: 0.8153 - val_loss: 1.3501 - val_accuracy: 0.7532\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6066 - accuracy: 0.8188 - val_loss: 1.2255 - val_accuracy: 0.7922\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4917 - accuracy: 0.8397 - val_loss: 1.1483 - val_accuracy: 0.8182\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4616 - accuracy: 0.8676 - val_loss: 1.1708 - val_accuracy: 0.8182\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4488 - accuracy: 0.8815 - val_loss: 1.1727 - val_accuracy: 0.8182\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4420 - accuracy: 0.8746 - val_loss: 1.2129 - val_accuracy: 0.7922\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4424 - accuracy: 0.8676 - val_loss: 1.1982 - val_accuracy: 0.8182\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4642 - accuracy: 0.8746 - val_loss: 1.2575 - val_accuracy: 0.7922\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4504 - accuracy: 0.8955 - val_loss: 1.2014 - val_accuracy: 0.8182\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4699 - accuracy: 0.8537 - val_loss: 1.2929 - val_accuracy: 0.7922\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4505 - accuracy: 0.8850 - val_loss: 1.1430 - val_accuracy: 0.8312\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4882 - accuracy: 0.8537 - val_loss: 1.4115 - val_accuracy: 0.7662\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4913 - accuracy: 0.8537 - val_loss: 1.0070 - val_accuracy: 0.8442\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5960 - accuracy: 0.8084 - val_loss: 1.6640 - val_accuracy: 0.7662\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8798 - accuracy: 0.7805 - val_loss: 0.9270 - val_accuracy: 0.8052\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1058 - accuracy: 0.6516 - val_loss: 1.9497 - val_accuracy: 0.7013\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1700 - accuracy: 0.6167 - val_loss: 1.5339 - val_accuracy: 0.6234\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2539 - accuracy: 0.6307 - val_loss: 1.9882 - val_accuracy: 0.6753\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8777 - accuracy: 0.7596 - val_loss: 1.2615 - val_accuracy: 0.7273\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5302 - accuracy: 0.8711 - val_loss: 1.2100 - val_accuracy: 0.7532\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4597 - accuracy: 0.8571 - val_loss: 0.7433 - val_accuracy: 0.8571\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3297 - accuracy: 0.9094 - val_loss: 0.7655 - val_accuracy: 0.8312\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3125 - accuracy: 0.9094 - val_loss: 0.7677 - val_accuracy: 0.8571\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3022 - accuracy: 0.9443 - val_loss: 0.7713 - val_accuracy: 0.8442\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2937 - accuracy: 0.9199 - val_loss: 0.7839 - val_accuracy: 0.8442\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2886 - accuracy: 0.9129 - val_loss: 0.7832 - val_accuracy: 0.8442\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2946 - accuracy: 0.9059 - val_loss: 0.8140 - val_accuracy: 0.8571\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3216 - accuracy: 0.9164 - val_loss: 0.8298 - val_accuracy: 0.8442\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3430 - accuracy: 0.8885 - val_loss: 0.8068 - val_accuracy: 0.8182\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3256 - accuracy: 0.8850 - val_loss: 0.8602 - val_accuracy: 0.8571\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3574 - accuracy: 0.9094 - val_loss: 0.7463 - val_accuracy: 0.8442\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3058 - accuracy: 0.9094 - val_loss: 0.8563 - val_accuracy: 0.8571\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3294 - accuracy: 0.9233 - val_loss: 0.6977 - val_accuracy: 0.8571\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3117 - accuracy: 0.8885 - val_loss: 1.0050 - val_accuracy: 0.8312\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3837 - accuracy: 0.8850 - val_loss: 0.5679 - val_accuracy: 0.8312\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8804 - accuracy: 0.7108 - val_loss: 2.2761 - val_accuracy: 0.6753\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.9561 - accuracy: 0.5714 - val_loss: 2.7661 - val_accuracy: 0.6234\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.8363 - accuracy: 0.6237 - val_loss: 1.1633 - val_accuracy: 0.7273\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6694 - accuracy: 0.7840 - val_loss: 1.4637 - val_accuracy: 0.6753\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5153 - accuracy: 0.9094 - val_loss: 0.9509 - val_accuracy: 0.7792\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3682 - accuracy: 0.9268 - val_loss: 0.8112 - val_accuracy: 0.8052\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3157 - accuracy: 0.9338 - val_loss: 0.7807 - val_accuracy: 0.8052\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2891 - accuracy: 0.9303 - val_loss: 0.7677 - val_accuracy: 0.8052\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2778 - accuracy: 0.9373 - val_loss: 0.7788 - val_accuracy: 0.8052\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2675 - accuracy: 0.9303 - val_loss: 0.7931 - val_accuracy: 0.8052\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2591 - accuracy: 0.9373 - val_loss: 0.7946 - val_accuracy: 0.8052\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2517 - accuracy: 0.9303 - val_loss: 0.8164 - val_accuracy: 0.8052\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2464 - accuracy: 0.9443 - val_loss: 0.8061 - val_accuracy: 0.8052\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2477 - accuracy: 0.9233 - val_loss: 0.8682 - val_accuracy: 0.8052\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2584 - accuracy: 0.9408 - val_loss: 0.7735 - val_accuracy: 0.8052\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2915 - accuracy: 0.9024 - val_loss: 0.9630 - val_accuracy: 0.8052\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3122 - accuracy: 0.9199 - val_loss: 0.7275 - val_accuracy: 0.8701\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3450 - accuracy: 0.8955 - val_loss: 0.9912 - val_accuracy: 0.8052\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3093 - accuracy: 0.8955 - val_loss: 0.5426 - val_accuracy: 0.8701\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5951 - accuracy: 0.8084 - val_loss: 1.5896 - val_accuracy: 0.7273\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9229 - accuracy: 0.7073 - val_loss: 1.8841 - val_accuracy: 0.6494\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5927 - accuracy: 0.6028 - val_loss: 1.5356 - val_accuracy: 0.8052\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6868 - accuracy: 0.7770 - val_loss: 2.1399 - val_accuracy: 0.6364\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5974 - accuracy: 0.8676 - val_loss: 1.8178 - val_accuracy: 0.7273\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6562 - accuracy: 0.9059 - val_loss: 1.1018 - val_accuracy: 0.7792\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3754 - accuracy: 0.9059 - val_loss: 1.3540 - val_accuracy: 0.7532\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3785 - accuracy: 0.9408 - val_loss: 0.9287 - val_accuracy: 0.7532\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2550 - accuracy: 0.9408 - val_loss: 0.9050 - val_accuracy: 0.7792\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2254 - accuracy: 0.9617 - val_loss: 0.8782 - val_accuracy: 0.7792\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2159 - accuracy: 0.9477 - val_loss: 0.8963 - val_accuracy: 0.7792\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2087 - accuracy: 0.9756 - val_loss: 0.8740 - val_accuracy: 0.7792\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2073 - accuracy: 0.9408 - val_loss: 0.9268 - val_accuracy: 0.7792\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2110 - accuracy: 0.9617 - val_loss: 0.8570 - val_accuracy: 0.8052\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2424 - accuracy: 0.9268 - val_loss: 1.0205 - val_accuracy: 0.7792\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2562 - accuracy: 0.9338 - val_loss: 0.6920 - val_accuracy: 0.8571\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3369 - accuracy: 0.8780 - val_loss: 1.3793 - val_accuracy: 0.7662\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5476 - accuracy: 0.8641 - val_loss: 1.2473 - val_accuracy: 0.7532\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0585 - accuracy: 0.7247 - val_loss: 1.8844 - val_accuracy: 0.7662\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2384 - accuracy: 0.6585 - val_loss: 1.6067 - val_accuracy: 0.6753\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9837 - accuracy: 0.6969 - val_loss: 1.2197 - val_accuracy: 0.7662\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5451 - accuracy: 0.8676 - val_loss: 0.7955 - val_accuracy: 0.8442\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3883 - accuracy: 0.9059 - val_loss: 0.8155 - val_accuracy: 0.8571\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2673 - accuracy: 0.9686 - val_loss: 0.7657 - val_accuracy: 0.8571\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2382 - accuracy: 0.9686 - val_loss: 0.7708 - val_accuracy: 0.8571\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2179 - accuracy: 0.9686 - val_loss: 0.7757 - val_accuracy: 0.8571\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2034 - accuracy: 0.9617 - val_loss: 0.7726 - val_accuracy: 0.8571\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1960 - accuracy: 0.9686 - val_loss: 0.7949 - val_accuracy: 0.8831\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1879 - accuracy: 0.9756 - val_loss: 0.8158 - val_accuracy: 0.8571\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1818 - accuracy: 0.9686 - val_loss: 0.8161 - val_accuracy: 0.8831\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1762 - accuracy: 0.9756 - val_loss: 0.8811 - val_accuracy: 0.8831\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1754 - accuracy: 0.9686 - val_loss: 0.7756 - val_accuracy: 0.8831\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2007 - accuracy: 0.9408 - val_loss: 1.0383 - val_accuracy: 0.8831\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2862 - accuracy: 0.9303 - val_loss: 0.5833 - val_accuracy: 0.9091\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6560 - accuracy: 0.7805 - val_loss: 1.9417 - val_accuracy: 0.7273\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1514 - accuracy: 0.6969 - val_loss: 1.6395 - val_accuracy: 0.6883\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2419 - accuracy: 0.6969 - val_loss: 1.6429 - val_accuracy: 0.7792\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7013 - accuracy: 0.7979 - val_loss: 0.8162 - val_accuracy: 0.7662\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3313 - accuracy: 0.9199 - val_loss: 0.8573 - val_accuracy: 0.8312\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2361 - accuracy: 0.9756 - val_loss: 0.8779 - val_accuracy: 0.7792\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2091 - accuracy: 0.9686 - val_loss: 0.8402 - val_accuracy: 0.8831\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1848 - accuracy: 0.9756 - val_loss: 0.8224 - val_accuracy: 0.8831\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1747 - accuracy: 0.9756 - val_loss: 0.8513 - val_accuracy: 0.8831\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1667 - accuracy: 0.9756 - val_loss: 0.8462 - val_accuracy: 0.8831\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1598 - accuracy: 0.9756 - val_loss: 0.8774 - val_accuracy: 0.8831\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1533 - accuracy: 0.9826 - val_loss: 0.8764 - val_accuracy: 0.8831\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1474 - accuracy: 0.9756 - val_loss: 0.9136 - val_accuracy: 0.8831\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1420 - accuracy: 0.9826 - val_loss: 0.9076 - val_accuracy: 0.8831\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1374 - accuracy: 0.9756 - val_loss: 0.9708 - val_accuracy: 0.8831\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1362 - accuracy: 0.9826 - val_loss: 0.9268 - val_accuracy: 0.8831\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1437 - accuracy: 0.9617 - val_loss: 1.0568 - val_accuracy: 0.8831\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1528 - accuracy: 0.9617 - val_loss: 0.9612 - val_accuracy: 0.8831\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1448 - accuracy: 0.9617 - val_loss: 1.1002 - val_accuracy: 0.8831\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1335 - accuracy: 0.9617 - val_loss: 0.8585 - val_accuracy: 0.8961\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1641 - accuracy: 0.9199 - val_loss: 1.2861 - val_accuracy: 0.8571\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4163 - accuracy: 0.9094 - val_loss: 0.9016 - val_accuracy: 0.8571\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8258 - accuracy: 0.7213 - val_loss: 2.6987 - val_accuracy: 0.6623\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0194 - accuracy: 0.6132 - val_loss: 3.5099 - val_accuracy: 0.5844\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7999 - accuracy: 0.6307 - val_loss: 2.8243 - val_accuracy: 0.5974\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8544 - accuracy: 0.8118 - val_loss: 1.5912 - val_accuracy: 0.7662\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5790 - accuracy: 0.9024 - val_loss: 1.4176 - val_accuracy: 0.8052\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3678 - accuracy: 0.9512 - val_loss: 1.3212 - val_accuracy: 0.8052\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2844 - accuracy: 0.9652 - val_loss: 1.2226 - val_accuracy: 0.8052\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2457 - accuracy: 0.9756 - val_loss: 0.8609 - val_accuracy: 0.8571\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1492 - accuracy: 0.9826 - val_loss: 0.8607 - val_accuracy: 0.8571\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1426 - accuracy: 0.9826 - val_loss: 0.8692 - val_accuracy: 0.8831\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1378 - accuracy: 0.9826 - val_loss: 0.8794 - val_accuracy: 0.8831\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1336 - accuracy: 0.9826 - val_loss: 0.8904 - val_accuracy: 0.8831\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1296 - accuracy: 0.9826 - val_loss: 0.9019 - val_accuracy: 0.8831\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1259 - accuracy: 0.9826 - val_loss: 0.9148 - val_accuracy: 0.8831\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1223 - accuracy: 0.9826 - val_loss: 0.9275 - val_accuracy: 0.8831\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1190 - accuracy: 0.9826 - val_loss: 0.9407 - val_accuracy: 0.8831\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1158 - accuracy: 0.9826 - val_loss: 0.9552 - val_accuracy: 0.8831\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1126 - accuracy: 0.9826 - val_loss: 0.9702 - val_accuracy: 0.8831\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1096 - accuracy: 0.9826 - val_loss: 0.9843 - val_accuracy: 0.8961\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1068 - accuracy: 0.9930 - val_loss: 1.0047 - val_accuracy: 0.8961\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1042 - accuracy: 0.9930 - val_loss: 1.0161 - val_accuracy: 0.8961\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1027 - accuracy: 0.9930 - val_loss: 1.0490 - val_accuracy: 0.8961\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1078 - accuracy: 0.9861 - val_loss: 1.0706 - val_accuracy: 0.8961\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1380 - accuracy: 0.9721 - val_loss: 1.0517 - val_accuracy: 0.8961\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1419 - accuracy: 0.9721 - val_loss: 1.1773 - val_accuracy: 0.8961\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1288 - accuracy: 0.9721 - val_loss: 0.6961 - val_accuracy: 0.9481\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5220 - accuracy: 0.8885 - val_loss: 3.0145 - val_accuracy: 0.7143\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2690 - accuracy: 0.6376 - val_loss: 2.1993 - val_accuracy: 0.7532\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3655 - accuracy: 0.7422 - val_loss: 2.1539 - val_accuracy: 0.7792\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8825 - accuracy: 0.8153 - val_loss: 1.2667 - val_accuracy: 0.8182\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6841 - accuracy: 0.8537 - val_loss: 1.2604 - val_accuracy: 0.8701\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4211 - accuracy: 0.9094 - val_loss: 0.7434 - val_accuracy: 0.9091\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2496 - accuracy: 0.9512 - val_loss: 1.0142 - val_accuracy: 0.8701\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1848 - accuracy: 0.9721 - val_loss: 0.7689 - val_accuracy: 0.8961\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1647 - accuracy: 0.9791 - val_loss: 0.8898 - val_accuracy: 0.8961\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1360 - accuracy: 0.9930 - val_loss: 0.8609 - val_accuracy: 0.8961\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1267 - accuracy: 0.9930 - val_loss: 0.8717 - val_accuracy: 0.8961\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1215 - accuracy: 0.9930 - val_loss: 0.8820 - val_accuracy: 0.8961\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1175 - accuracy: 0.9930 - val_loss: 0.8916 - val_accuracy: 0.8961\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1138 - accuracy: 0.9930 - val_loss: 0.9024 - val_accuracy: 0.8961\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1102 - accuracy: 0.9930 - val_loss: 0.9123 - val_accuracy: 0.8961\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1068 - accuracy: 0.9930 - val_loss: 0.9272 - val_accuracy: 0.8961\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1036 - accuracy: 0.9930 - val_loss: 0.9368 - val_accuracy: 0.8961\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1004 - accuracy: 0.9930 - val_loss: 0.9573 - val_accuracy: 0.8961\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0974 - accuracy: 0.9930 - val_loss: 0.9621 - val_accuracy: 0.8961\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0946 - accuracy: 0.9930 - val_loss: 0.9931 - val_accuracy: 0.8831\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0921 - accuracy: 0.9826 - val_loss: 0.9853 - val_accuracy: 0.8961\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0901 - accuracy: 0.9930 - val_loss: 1.0463 - val_accuracy: 0.8961\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0913 - accuracy: 0.9930 - val_loss: 0.9933 - val_accuracy: 0.8961\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1052 - accuracy: 0.9861 - val_loss: 1.1166 - val_accuracy: 0.8831\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1040 - accuracy: 0.9756 - val_loss: 1.0613 - val_accuracy: 0.8961\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0923 - accuracy: 0.9861 - val_loss: 1.0189 - val_accuracy: 0.8961\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0852 - accuracy: 0.9930 - val_loss: 1.1094 - val_accuracy: 0.8961\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0871 - accuracy: 0.9861 - val_loss: 0.8676 - val_accuracy: 0.9221\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2023 - accuracy: 0.9512 - val_loss: 1.5973 - val_accuracy: 0.8571\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8825 - accuracy: 0.8084 - val_loss: 1.5164 - val_accuracy: 0.7922\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2650 - accuracy: 0.6551 - val_loss: 2.5235 - val_accuracy: 0.7273\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4360 - accuracy: 0.6969 - val_loss: 3.6664 - val_accuracy: 0.5325\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1285 - accuracy: 0.7700 - val_loss: 2.0628 - val_accuracy: 0.7403\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3845 - accuracy: 0.9512 - val_loss: 1.2533 - val_accuracy: 0.7662\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1673 - accuracy: 0.9756 - val_loss: 1.0352 - val_accuracy: 0.8442\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1838 - accuracy: 0.9826 - val_loss: 1.0171 - val_accuracy: 0.8442\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1118 - accuracy: 0.9930 - val_loss: 1.0105 - val_accuracy: 0.8701\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1058 - accuracy: 0.9930 - val_loss: 1.0159 - val_accuracy: 0.8701\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1017 - accuracy: 0.9930 - val_loss: 1.0234 - val_accuracy: 0.8701\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0981 - accuracy: 0.9930 - val_loss: 1.0324 - val_accuracy: 0.8701\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0948 - accuracy: 0.9930 - val_loss: 1.0421 - val_accuracy: 0.8701\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0918 - accuracy: 0.9930 - val_loss: 1.0524 - val_accuracy: 0.8701\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0889 - accuracy: 0.9930 - val_loss: 1.0635 - val_accuracy: 0.8701\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0862 - accuracy: 0.9930 - val_loss: 1.0728 - val_accuracy: 0.8701\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0836 - accuracy: 0.9930 - val_loss: 1.0820 - val_accuracy: 0.8701\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0811 - accuracy: 0.9930 - val_loss: 1.0862 - val_accuracy: 0.8701\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0788 - accuracy: 0.9930 - val_loss: 1.0925 - val_accuracy: 0.8701\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0764 - accuracy: 0.9930 - val_loss: 1.0970 - val_accuracy: 0.8701\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0742 - accuracy: 0.9930 - val_loss: 1.1054 - val_accuracy: 0.8701\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0720 - accuracy: 0.9930 - val_loss: 1.1104 - val_accuracy: 0.8701\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0699 - accuracy: 0.9930 - val_loss: 1.1199 - val_accuracy: 0.8701\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0679 - accuracy: 0.9930 - val_loss: 1.1260 - val_accuracy: 0.8701\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0658 - accuracy: 0.9930 - val_loss: 1.1361 - val_accuracy: 0.8701\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0639 - accuracy: 0.9930 - val_loss: 1.1435 - val_accuracy: 0.8701\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0624 - accuracy: 0.9930 - val_loss: 1.1591 - val_accuracy: 0.8701\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0618 - accuracy: 0.9930 - val_loss: 1.1588 - val_accuracy: 0.8701\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0689 - accuracy: 0.9861 - val_loss: 1.3378 - val_accuracy: 0.8442\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1065 - accuracy: 0.9791 - val_loss: 1.4138 - val_accuracy: 0.8312\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3465 - accuracy: 0.9477 - val_loss: 1.6334 - val_accuracy: 0.8312\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3628 - accuracy: 0.9547 - val_loss: 1.4901 - val_accuracy: 0.8442\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6047 - accuracy: 0.8955 - val_loss: 2.3303 - val_accuracy: 0.7532\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8780 - accuracy: 0.6829 - val_loss: 2.9958 - val_accuracy: 0.6883\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.7573 - accuracy: 0.7038 - val_loss: 2.8406 - val_accuracy: 0.7013\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2206 - accuracy: 0.7422 - val_loss: 2.7685 - val_accuracy: 0.6364\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7531 - accuracy: 0.8084 - val_loss: 1.7260 - val_accuracy: 0.7013\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2873 - accuracy: 0.9129 - val_loss: 1.3549 - val_accuracy: 0.7922\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1508 - accuracy: 0.9826 - val_loss: 1.3772 - val_accuracy: 0.7662\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1148 - accuracy: 0.9826 - val_loss: 1.2010 - val_accuracy: 0.7922\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1056 - accuracy: 0.9861 - val_loss: 1.2098 - val_accuracy: 0.7922\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0917 - accuracy: 0.9930 - val_loss: 1.1872 - val_accuracy: 0.7922\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0869 - accuracy: 0.9930 - val_loss: 1.1890 - val_accuracy: 0.8182\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0828 - accuracy: 0.9930 - val_loss: 1.1888 - val_accuracy: 0.8182\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0801 - accuracy: 0.9930 - val_loss: 1.1910 - val_accuracy: 0.8182\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0777 - accuracy: 0.9930 - val_loss: 1.1930 - val_accuracy: 0.8182\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0753 - accuracy: 0.9930 - val_loss: 1.1940 - val_accuracy: 0.8182\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0731 - accuracy: 0.9930 - val_loss: 1.1927 - val_accuracy: 0.8182\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0710 - accuracy: 0.9930 - val_loss: 1.1874 - val_accuracy: 0.8182\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0688 - accuracy: 0.9930 - val_loss: 1.1812 - val_accuracy: 0.8182\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0667 - accuracy: 0.9930 - val_loss: 1.1787 - val_accuracy: 0.8182\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0648 - accuracy: 0.9930 - val_loss: 1.1778 - val_accuracy: 0.8442\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0629 - accuracy: 0.9930 - val_loss: 1.1771 - val_accuracy: 0.8442\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0610 - accuracy: 0.9930 - val_loss: 1.1807 - val_accuracy: 0.8442\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0592 - accuracy: 0.9930 - val_loss: 1.1821 - val_accuracy: 0.8442\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0574 - accuracy: 0.9930 - val_loss: 1.1856 - val_accuracy: 0.8442\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0557 - accuracy: 0.9930 - val_loss: 1.1897 - val_accuracy: 0.8442\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0539 - accuracy: 0.9930 - val_loss: 1.1969 - val_accuracy: 0.8442\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0523 - accuracy: 0.9930 - val_loss: 1.2019 - val_accuracy: 0.8442\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0506 - accuracy: 0.9930 - val_loss: 1.2112 - val_accuracy: 0.8442\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0491 - accuracy: 0.9930 - val_loss: 1.2179 - val_accuracy: 0.8442\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0475 - accuracy: 0.9930 - val_loss: 1.2278 - val_accuracy: 0.8442\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0461 - accuracy: 0.9930 - val_loss: 1.2257 - val_accuracy: 0.8442\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0447 - accuracy: 0.9930 - val_loss: 1.2488 - val_accuracy: 0.8442\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0434 - accuracy: 0.9930 - val_loss: 1.2349 - val_accuracy: 0.8442\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0422 - accuracy: 0.9930 - val_loss: 1.2745 - val_accuracy: 0.8442\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0410 - accuracy: 0.9930 - val_loss: 1.2431 - val_accuracy: 0.8442\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0402 - accuracy: 0.9930 - val_loss: 1.3025 - val_accuracy: 0.8442\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0400 - accuracy: 0.9930 - val_loss: 1.2533 - val_accuracy: 0.8442\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0394 - accuracy: 0.9930 - val_loss: 1.3187 - val_accuracy: 0.8442\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0389 - accuracy: 0.9930 - val_loss: 1.2901 - val_accuracy: 0.8442\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0361 - accuracy: 0.9930 - val_loss: 1.3346 - val_accuracy: 0.8442\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0342 - accuracy: 0.9930 - val_loss: 1.3176 - val_accuracy: 0.8442\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0323 - accuracy: 0.9930 - val_loss: 1.3370 - val_accuracy: 0.8442\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0314 - accuracy: 0.9930 - val_loss: 1.3805 - val_accuracy: 0.8182\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0348 - accuracy: 0.9861 - val_loss: 1.2119 - val_accuracy: 0.8442\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1325 - accuracy: 0.9791 - val_loss: 2.4039 - val_accuracy: 0.7922\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5460 - accuracy: 0.7944 - val_loss: 2.4174 - val_accuracy: 0.7403\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.9546 - accuracy: 0.6760 - val_loss: 3.3280 - val_accuracy: 0.6623\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.9271 - accuracy: 0.6620 - val_loss: 5.3301 - val_accuracy: 0.5844\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.9510 - accuracy: 0.7213 - val_loss: 2.7132 - val_accuracy: 0.7662\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1395 - accuracy: 0.8955 - val_loss: 1.9301 - val_accuracy: 0.7792\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5499 - accuracy: 0.9233 - val_loss: 1.6656 - val_accuracy: 0.8052\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3562 - accuracy: 0.9547 - val_loss: 1.4573 - val_accuracy: 0.8442\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4063 - accuracy: 0.9652 - val_loss: 1.4956 - val_accuracy: 0.8182\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4075 - accuracy: 0.9582 - val_loss: 1.3657 - val_accuracy: 0.8571\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5050 - accuracy: 0.9582 - val_loss: 1.4595 - val_accuracy: 0.8442\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3579 - accuracy: 0.9721 - val_loss: 1.6680 - val_accuracy: 0.8312\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3527 - accuracy: 0.9686 - val_loss: 1.6959 - val_accuracy: 0.8312\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3310 - accuracy: 0.9756 - val_loss: 1.6865 - val_accuracy: 0.8312\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3279 - accuracy: 0.9756 - val_loss: 1.6860 - val_accuracy: 0.8312\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3263 - accuracy: 0.9756 - val_loss: 1.6850 - val_accuracy: 0.8312\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3249 - accuracy: 0.9756 - val_loss: 1.6861 - val_accuracy: 0.8312\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3237 - accuracy: 0.9756 - val_loss: 1.6872 - val_accuracy: 0.8312\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3226 - accuracy: 0.9756 - val_loss: 1.6895 - val_accuracy: 0.8312\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3215 - accuracy: 0.9756 - val_loss: 1.6913 - val_accuracy: 0.8312\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3204 - accuracy: 0.9756 - val_loss: 1.6937 - val_accuracy: 0.8312\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3194 - accuracy: 0.9756 - val_loss: 1.6972 - val_accuracy: 0.8312\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3185 - accuracy: 0.9756 - val_loss: 1.6999 - val_accuracy: 0.8312\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3175 - accuracy: 0.9756 - val_loss: 1.7028 - val_accuracy: 0.8312\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3166 - accuracy: 0.9756 - val_loss: 1.7071 - val_accuracy: 0.8312\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3157 - accuracy: 0.9756 - val_loss: 1.7104 - val_accuracy: 0.8312\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3148 - accuracy: 0.9756 - val_loss: 1.7137 - val_accuracy: 0.8312\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3139 - accuracy: 0.9756 - val_loss: 1.7174 - val_accuracy: 0.8312\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3131 - accuracy: 0.9756 - val_loss: 1.7202 - val_accuracy: 0.8312\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3122 - accuracy: 0.9756 - val_loss: 1.7236 - val_accuracy: 0.8312\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3114 - accuracy: 0.9756 - val_loss: 1.7264 - val_accuracy: 0.8312\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3106 - accuracy: 0.9756 - val_loss: 1.7320 - val_accuracy: 0.8312\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3098 - accuracy: 0.9756 - val_loss: 1.7346 - val_accuracy: 0.8312\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3090 - accuracy: 0.9756 - val_loss: 1.7364 - val_accuracy: 0.8312\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3082 - accuracy: 0.9756 - val_loss: 1.7408 - val_accuracy: 0.8312\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3074 - accuracy: 0.9756 - val_loss: 1.7468 - val_accuracy: 0.8312\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3067 - accuracy: 0.9756 - val_loss: 1.7487 - val_accuracy: 0.8312\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3060 - accuracy: 0.9756 - val_loss: 1.7536 - val_accuracy: 0.8312\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3052 - accuracy: 0.9756 - val_loss: 1.7544 - val_accuracy: 0.8312\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3045 - accuracy: 0.9756 - val_loss: 1.7596 - val_accuracy: 0.8312\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3038 - accuracy: 0.9756 - val_loss: 1.7662 - val_accuracy: 0.8312\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3031 - accuracy: 0.9756 - val_loss: 1.7663 - val_accuracy: 0.8312\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3024 - accuracy: 0.9756 - val_loss: 1.7717 - val_accuracy: 0.8312\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3017 - accuracy: 0.9756 - val_loss: 1.7765 - val_accuracy: 0.8312\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3010 - accuracy: 0.9756 - val_loss: 1.7802 - val_accuracy: 0.8312\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3003 - accuracy: 0.9756 - val_loss: 1.7866 - val_accuracy: 0.8312\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2997 - accuracy: 0.9756 - val_loss: 1.7915 - val_accuracy: 0.8312\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2990 - accuracy: 0.9756 - val_loss: 1.7938 - val_accuracy: 0.8312\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2984 - accuracy: 0.9756 - val_loss: 1.7987 - val_accuracy: 0.8312\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2977 - accuracy: 0.9756 - val_loss: 1.8027 - val_accuracy: 0.8312\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2971 - accuracy: 0.9756 - val_loss: 1.8068 - val_accuracy: 0.8312\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2965 - accuracy: 0.9756 - val_loss: 1.8049 - val_accuracy: 0.8312\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2959 - accuracy: 0.9756 - val_loss: 1.8087 - val_accuracy: 0.8312\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2953 - accuracy: 0.9756 - val_loss: 1.8129 - val_accuracy: 0.8312\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2947 - accuracy: 0.9756 - val_loss: 1.8120 - val_accuracy: 0.8312\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2942 - accuracy: 0.9756 - val_loss: 1.8107 - val_accuracy: 0.8442\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2942 - accuracy: 0.9756 - val_loss: 1.8441 - val_accuracy: 0.8312\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2954 - accuracy: 0.9756 - val_loss: 1.7181 - val_accuracy: 0.8571\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3316 - accuracy: 0.9686 - val_loss: 4.2339 - val_accuracy: 0.6883\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.6795 - accuracy: 0.6516 - val_loss: 4.2883 - val_accuracy: 0.6753\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.8075 - accuracy: 0.6794 - val_loss: 5.0582 - val_accuracy: 0.6104\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.2515 - accuracy: 0.5923 - val_loss: 4.9328 - val_accuracy: 0.6364\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1975 - accuracy: 0.7422 - val_loss: 3.1971 - val_accuracy: 0.7532\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.6709 - accuracy: 0.7770 - val_loss: 3.1316 - val_accuracy: 0.7532\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3406 - accuracy: 0.8188 - val_loss: 2.9580 - val_accuracy: 0.7532\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6717 - accuracy: 0.8571 - val_loss: 2.8981 - val_accuracy: 0.7403\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3676 - accuracy: 0.8258 - val_loss: 2.7186 - val_accuracy: 0.7532\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4311 - accuracy: 0.8153 - val_loss: 2.1012 - val_accuracy: 0.8182\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0062 - accuracy: 0.9129 - val_loss: 2.4610 - val_accuracy: 0.7532\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "model\n",
    "\n",
    "### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "#    - input_dim : 말뭉치갯수\n",
    "#    - 출력갯수 : 64개\n",
    "#    - input_length : 질문의 특성 갯수\n",
    "model.add(\n",
    "    keras.layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=64,\n",
    "                           input_length=questions_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 추가 : GRU, 출력:128, 활성화함수:relu\n",
    "# - 질문을 담당하는 계층\n",
    "model.add(\n",
    "    keras.layers.GRU(units=128, activation=\"relu\")\n",
    ")\n",
    "\n",
    "### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "# - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "model.add(\n",
    "    keras.layers.RepeatVector(answers_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 : GRU 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "# - return_sequences=True : 훈련결과(단어)를 다음 계층으로 넘겨주기\n",
    "#                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행\n",
    "model.add(\n",
    "    keras.layers.GRU(units=128, activation=\"relu\", return_sequences=True)\n",
    ")\n",
    "\n",
    "### 단어조합 계층과 출력계층 정의하기\n",
    "# TimeDistributed \n",
    "#  - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "#  - 다음에 올 단어들이 있는지 체크\n",
    "#  - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "#  - 출력계층을 감싸서 사용\n",
    "# ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환\n",
    "model.add(\n",
    "    keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(units=vocab_size, activation=\"softmax\")\n",
    "    )\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - rmsprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=\"RMSprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.h5\n",
    "save_file = \"./model/best_RNN_chatbot.h5\"\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(save_file, save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수 : 600회, 배치사이즈:64\n",
    "history = model.fit(\n",
    "    questions_train, answers_train, epochs=600, batch_size=64, \n",
    "    validation_data=(questions_val, answers_val)\n",
    "    # , callbacks=[cp_cb, es_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e61ca89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 손실 곡선\n",
    "plt.plot(history.epoch, history.history[\"loss\"])\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda1abae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 정확도 곡선\n",
    "plt.plot(history.epoch, history.history[\"accuracy\"])\n",
    "plt.plot(history.epoch, history.history[\"val_accuracy\"])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6227c357",
   "metadata": {},
   "source": [
    "### 가장 성능 좋은 시점의 모델 계층 및 하이퍼파라메터를 이용하여 전제데이터 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ceff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 6, 64)             4992      \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 128)               74496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 7, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 7, 128)            99072     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 7, 78)            10062     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,622\n",
      "Trainable params: 188,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.3567 - accuracy: 0.0027\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3242 - accuracy: 0.4148\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2733 - accuracy: 0.4148\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1823 - accuracy: 0.4148\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9954 - accuracy: 0.4148\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.6121 - accuracy: 0.4148\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8481 - accuracy: 0.4148\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.1822 - accuracy: 0.4148\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9991 - accuracy: 0.4148\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7093 - accuracy: 0.4148\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6841 - accuracy: 0.4148\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6645 - accuracy: 0.4148\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.6389 - accuracy: 0.4148\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6282 - accuracy: 0.4148\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6227 - accuracy: 0.4148\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5957 - accuracy: 0.4148\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5692 - accuracy: 0.4148\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5594 - accuracy: 0.4148\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5384 - accuracy: 0.4148\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5191 - accuracy: 0.4148\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5439 - accuracy: 0.4148\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.6483 - accuracy: 0.4176\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.6188 - accuracy: 0.4148\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5702 - accuracy: 0.4148\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4413 - accuracy: 0.4148\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4081 - accuracy: 0.4203\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3885 - accuracy: 0.4203\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3508 - accuracy: 0.4423\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3344 - accuracy: 0.4396\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3206 - accuracy: 0.4396\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3016 - accuracy: 0.4396\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3581 - accuracy: 0.4258\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.5390 - accuracy: 0.4478\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6302 - accuracy: 0.4368\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2664 - accuracy: 0.4478\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2230 - accuracy: 0.4478\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1938 - accuracy: 0.4533\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1685 - accuracy: 0.4341\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1406 - accuracy: 0.4588\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1147 - accuracy: 0.4560\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1374 - accuracy: 0.4753\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2964 - accuracy: 0.4478\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.4235 - accuracy: 0.4753\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3769 - accuracy: 0.4533\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0732 - accuracy: 0.4808\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0293 - accuracy: 0.4725\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9982 - accuracy: 0.4863\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9620 - accuracy: 0.4753\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9570 - accuracy: 0.4780\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0259 - accuracy: 0.4560\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2081 - accuracy: 0.4753\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3275 - accuracy: 0.4423\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0030 - accuracy: 0.4835\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9431 - accuracy: 0.4863\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.8644 - accuracy: 0.4808\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8188 - accuracy: 0.4973\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8162 - accuracy: 0.4780\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8694 - accuracy: 0.5247\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.1607 - accuracy: 0.4753\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3298 - accuracy: 0.3791\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8889 - accuracy: 0.4918\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7775 - accuracy: 0.5055\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7205 - accuracy: 0.4973\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6808 - accuracy: 0.5137\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6528 - accuracy: 0.5220\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6627 - accuracy: 0.4918\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7339 - accuracy: 0.5165\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8367 - accuracy: 0.4945\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.3656 - accuracy: 0.4808\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3148 - accuracy: 0.3901\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6983 - accuracy: 0.5357\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6276 - accuracy: 0.5385\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5739 - accuracy: 0.5165\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5342 - accuracy: 0.5632\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5227 - accuracy: 0.5330\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4842 - accuracy: 0.5247\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5225 - accuracy: 0.5220\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5644 - accuracy: 0.5604\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7924 - accuracy: 0.5027\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7710 - accuracy: 0.2802\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.1187 - accuracy: 0.5192\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6608 - accuracy: 0.5687\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5289 - accuracy: 0.5440\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5015 - accuracy: 0.5577\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4572 - accuracy: 0.5522\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4417 - accuracy: 0.5385\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4030 - accuracy: 0.5879\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4060 - accuracy: 0.5604\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4016 - accuracy: 0.5989\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3332 - accuracy: 0.5742\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2970 - accuracy: 0.6044\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3272 - accuracy: 0.5962\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4501 - accuracy: 0.5549\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8499 - accuracy: 0.4615\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8584 - accuracy: 0.4945\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2854 - accuracy: 0.3819\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4429 - accuracy: 0.5577\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3577 - accuracy: 0.6016\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3107 - accuracy: 0.5934\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2656 - accuracy: 0.6099\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2721 - accuracy: 0.6346\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2557 - accuracy: 0.6099\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2279 - accuracy: 0.5934\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2491 - accuracy: 0.6181\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2101 - accuracy: 0.6209\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1764 - accuracy: 0.6291\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2215 - accuracy: 0.5907\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3395 - accuracy: 0.6016\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5142 - accuracy: 0.5714\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.1161 - accuracy: 0.4231\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.7300 - accuracy: 0.5137\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7142 - accuracy: 0.4890\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3397 - accuracy: 0.5989\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2535 - accuracy: 0.6209\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2410 - accuracy: 0.6209\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1863 - accuracy: 0.6181\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1667 - accuracy: 0.6429\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1346 - accuracy: 0.6291\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1212 - accuracy: 0.6374\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1145 - accuracy: 0.6071\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1333 - accuracy: 0.6264\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1744 - accuracy: 0.6264\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3236 - accuracy: 0.5604\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4443 - accuracy: 0.4863\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1453 - accuracy: 0.2885\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4871 - accuracy: 0.5714\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2799 - accuracy: 0.6126\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1991 - accuracy: 0.6209\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1574 - accuracy: 0.6374\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1356 - accuracy: 0.6401\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1191 - accuracy: 0.6209\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1066 - accuracy: 0.6374\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1037 - accuracy: 0.6429\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0718 - accuracy: 0.6401\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0440 - accuracy: 0.6319\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0497 - accuracy: 0.6511\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0449 - accuracy: 0.6374\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0243 - accuracy: 0.6429\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0601 - accuracy: 0.6374\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2398 - accuracy: 0.6016\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.1511 - accuracy: 0.5082\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.8276 - accuracy: 0.2775\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3716 - accuracy: 0.5879\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1536 - accuracy: 0.6401\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0753 - accuracy: 0.6401\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0679 - accuracy: 0.6566\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0242 - accuracy: 0.6566\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0114 - accuracy: 0.6621\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9905 - accuracy: 0.6731\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9762 - accuracy: 0.6703\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0183 - accuracy: 0.6593\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0621 - accuracy: 0.6319\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1086 - accuracy: 0.6456\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4078 - accuracy: 0.5742\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9834 - accuracy: 0.3791\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9262 - accuracy: 0.5385\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3839 - accuracy: 0.5357\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1240 - accuracy: 0.6374\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0383 - accuracy: 0.6758\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9946 - accuracy: 0.6758\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9937 - accuracy: 0.6813\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9810 - accuracy: 0.6676\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9722 - accuracy: 0.6703\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9547 - accuracy: 0.6951\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9132 - accuracy: 0.6786\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9295 - accuracy: 0.6841\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9544 - accuracy: 0.6813\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0094 - accuracy: 0.6621\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0964 - accuracy: 0.6511\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1957 - accuracy: 0.5934\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1053 - accuracy: 0.5275\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5418 - accuracy: 0.3324\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3942 - accuracy: 0.6264\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0817 - accuracy: 0.6648\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0095 - accuracy: 0.6786\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9845 - accuracy: 0.6676\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9328 - accuracy: 0.7005\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9097 - accuracy: 0.6951\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9082 - accuracy: 0.6896\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8946 - accuracy: 0.6978\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8775 - accuracy: 0.6951\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8559 - accuracy: 0.7060\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8843 - accuracy: 0.6731\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8889 - accuracy: 0.6923\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0561 - accuracy: 0.6291\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3595 - accuracy: 0.5632\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3317 - accuracy: 0.5192\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9286 - accuracy: 0.4533\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3037 - accuracy: 0.6648\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9505 - accuracy: 0.6923\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8932 - accuracy: 0.7198\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8423 - accuracy: 0.7198\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8490 - accuracy: 0.7088\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8444 - accuracy: 0.7198\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8417 - accuracy: 0.7115\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8254 - accuracy: 0.7253\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8287 - accuracy: 0.7005\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7977 - accuracy: 0.7418\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8555 - accuracy: 0.6923\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9033 - accuracy: 0.6786\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9313 - accuracy: 0.6676\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2074 - accuracy: 0.6099\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6489 - accuracy: 0.5055\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8040 - accuracy: 0.4890\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1331 - accuracy: 0.6758\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8556 - accuracy: 0.7198\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8171 - accuracy: 0.7390\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7897 - accuracy: 0.7308\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7689 - accuracy: 0.7582\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7753 - accuracy: 0.7418\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7756 - accuracy: 0.7418\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7618 - accuracy: 0.7308\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7879 - accuracy: 0.7308\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7788 - accuracy: 0.7527\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7277 - accuracy: 0.7473\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7751 - accuracy: 0.7555\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8193 - accuracy: 0.7253\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8839 - accuracy: 0.7088\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8944 - accuracy: 0.7143\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9782 - accuracy: 0.6401\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4643 - accuracy: 0.5330\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0596 - accuracy: 0.4698\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1719 - accuracy: 0.6731\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8071 - accuracy: 0.7555\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7697 - accuracy: 0.7582\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7523 - accuracy: 0.7582\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7234 - accuracy: 0.7637\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7134 - accuracy: 0.7637\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7055 - accuracy: 0.7555\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6970 - accuracy: 0.7555\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7187 - accuracy: 0.7610\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6967 - accuracy: 0.7445\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7082 - accuracy: 0.7445\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7467 - accuracy: 0.7170\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7844 - accuracy: 0.7335\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7682 - accuracy: 0.7335\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8437 - accuracy: 0.6978\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7000 - accuracy: 0.5302\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5943 - accuracy: 0.5082\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2722 - accuracy: 0.5797\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8691 - accuracy: 0.7555\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7280 - accuracy: 0.7665\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7257 - accuracy: 0.7555\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7022 - accuracy: 0.7665\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7193 - accuracy: 0.7610\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6646 - accuracy: 0.7637\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6603 - accuracy: 0.7637\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6442 - accuracy: 0.7912\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6356 - accuracy: 0.7830\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6416 - accuracy: 0.7885\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6995 - accuracy: 0.7857\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6855 - accuracy: 0.7665\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6994 - accuracy: 0.7637\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7730 - accuracy: 0.7500\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7063 - accuracy: 0.7692\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7021 - accuracy: 0.7720\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7470 - accuracy: 0.7225\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3204 - accuracy: 0.6676\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4003 - accuracy: 0.4038\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2416 - accuracy: 0.5412\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9464 - accuracy: 0.6786\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7391 - accuracy: 0.7665\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6793 - accuracy: 0.7885\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6602 - accuracy: 0.7940\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6453 - accuracy: 0.7830\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6300 - accuracy: 0.8022\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6111 - accuracy: 0.8132\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6171 - accuracy: 0.8159\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6106 - accuracy: 0.8022\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6035 - accuracy: 0.8187\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6088 - accuracy: 0.7885\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6212 - accuracy: 0.8049\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6113 - accuracy: 0.7940\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6885 - accuracy: 0.7747\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6541 - accuracy: 0.7692\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6532 - accuracy: 0.7830\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6707 - accuracy: 0.7747\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8454 - accuracy: 0.7390\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3376 - accuracy: 0.5769\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8726 - accuracy: 0.5659\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1778 - accuracy: 0.5962\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8342 - accuracy: 0.7637\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6541 - accuracy: 0.7720\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6382 - accuracy: 0.7885\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5814 - accuracy: 0.8132\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5723 - accuracy: 0.8077\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5881 - accuracy: 0.8022\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5906 - accuracy: 0.8159\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5838 - accuracy: 0.7995\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5766 - accuracy: 0.8077\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7006 - accuracy: 0.7830\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6044 - accuracy: 0.8049\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5610 - accuracy: 0.8214\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5456 - accuracy: 0.8297\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5731 - accuracy: 0.7995\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5864 - accuracy: 0.7967\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7868 - accuracy: 0.7802\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9116 - accuracy: 0.6731\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1960 - accuracy: 0.6511\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6153 - accuracy: 0.5247\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3469 - accuracy: 0.6264\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7774 - accuracy: 0.7500\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6041 - accuracy: 0.7830\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5545 - accuracy: 0.8379\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5160 - accuracy: 0.8544\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5266 - accuracy: 0.8352\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5189 - accuracy: 0.8324\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4991 - accuracy: 0.8407\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4815 - accuracy: 0.8709\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5127 - accuracy: 0.8324\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4868 - accuracy: 0.8462\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5258 - accuracy: 0.8297\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6494 - accuracy: 0.8022\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6215 - accuracy: 0.7912\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5684 - accuracy: 0.8077\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6255 - accuracy: 0.7720\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8183 - accuracy: 0.7088\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6791 - accuracy: 0.6264\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3785 - accuracy: 0.5769\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8750 - accuracy: 0.7637\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5614 - accuracy: 0.8269\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5278 - accuracy: 0.8407\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5171 - accuracy: 0.8434\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4945 - accuracy: 0.8434\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4886 - accuracy: 0.8379\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4560 - accuracy: 0.8654\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4435 - accuracy: 0.8407\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4568 - accuracy: 0.8489\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4545 - accuracy: 0.8324\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4974 - accuracy: 0.8214\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4854 - accuracy: 0.8077\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5638 - accuracy: 0.8077\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5887 - accuracy: 0.7802\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7015 - accuracy: 0.7775\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8281 - accuracy: 0.6868\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3466 - accuracy: 0.6511\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5180 - accuracy: 0.6291\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6673 - accuracy: 0.7885\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5294 - accuracy: 0.7885\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4504 - accuracy: 0.8544\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4225 - accuracy: 0.8709\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4270 - accuracy: 0.8571\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4225 - accuracy: 0.8544\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3995 - accuracy: 0.8599\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4322 - accuracy: 0.8516\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4057 - accuracy: 0.8571\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4212 - accuracy: 0.8434\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4226 - accuracy: 0.8736\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4212 - accuracy: 0.8462\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4263 - accuracy: 0.8407\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3853 - accuracy: 0.8599\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4366 - accuracy: 0.8187\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4794 - accuracy: 0.8159\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5743 - accuracy: 0.8132\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8361 - accuracy: 0.7088\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6480 - accuracy: 0.6401\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8203 - accuracy: 0.7198\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5857 - accuracy: 0.8214\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3733 - accuracy: 0.8956\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3795 - accuracy: 0.8764\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3410 - accuracy: 0.8984\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3313 - accuracy: 0.9148\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3525 - accuracy: 0.8956\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3282 - accuracy: 0.8901\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3093 - accuracy: 0.8929\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3246 - accuracy: 0.8846\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3627 - accuracy: 0.8901\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3663 - accuracy: 0.8764\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3437 - accuracy: 0.8956\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3287 - accuracy: 0.8736\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3500 - accuracy: 0.8819\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5149 - accuracy: 0.8626\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4236 - accuracy: 0.8407\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3553 - accuracy: 0.8709\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3677 - accuracy: 0.8846\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5206 - accuracy: 0.8379\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8899 - accuracy: 0.7060\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6975 - accuracy: 0.6731\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7229 - accuracy: 0.7582\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4131 - accuracy: 0.8544\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2800 - accuracy: 0.9176\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2594 - accuracy: 0.9231\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2596 - accuracy: 0.9423\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2313 - accuracy: 0.9451\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2966 - accuracy: 0.8984\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2623 - accuracy: 0.9231\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2453 - accuracy: 0.9341\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2548 - accuracy: 0.9396\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2488 - accuracy: 0.9176\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2390 - accuracy: 0.9203\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2386 - accuracy: 0.9148\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2388 - accuracy: 0.9286\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3417 - accuracy: 0.8984\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5060 - accuracy: 0.8544\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5729 - accuracy: 0.8242\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5515 - accuracy: 0.8626\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3951 - accuracy: 0.8571\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5816 - accuracy: 0.8269\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7686 - accuracy: 0.7445\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0378 - accuracy: 0.7170\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3875 - accuracy: 0.8709\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2467 - accuracy: 0.9341\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2371 - accuracy: 0.9341\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1996 - accuracy: 0.9396\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1852 - accuracy: 0.9615\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1997 - accuracy: 0.9451\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1914 - accuracy: 0.9396\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1754 - accuracy: 0.9615\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1638 - accuracy: 0.9588\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1952 - accuracy: 0.9533\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1989 - accuracy: 0.9451\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1777 - accuracy: 0.9588\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1737 - accuracy: 0.9643\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1734 - accuracy: 0.9698\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2014 - accuracy: 0.9203\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2006 - accuracy: 0.9368\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2070 - accuracy: 0.9313\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2305 - accuracy: 0.9368\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4351 - accuracy: 0.8516\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1480 - accuracy: 0.7390\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5081 - accuracy: 0.7033\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6446 - accuracy: 0.8187\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2850 - accuracy: 0.9341\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1956 - accuracy: 0.9423\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2032 - accuracy: 0.9533\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1726 - accuracy: 0.9505\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1745 - accuracy: 0.9615\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1529 - accuracy: 0.9588\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1522 - accuracy: 0.9725\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1446 - accuracy: 0.9780\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1461 - accuracy: 0.9588\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1341 - accuracy: 0.9808\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1342 - accuracy: 0.9780\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1383 - accuracy: 0.9670\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1184 - accuracy: 0.9780\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1300 - accuracy: 0.9670\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1262 - accuracy: 0.9670\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1363 - accuracy: 0.9588\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1599 - accuracy: 0.9615\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1492 - accuracy: 0.9615\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1239 - accuracy: 0.9808\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1308 - accuracy: 0.9670\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1175 - accuracy: 0.9698\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1912 - accuracy: 0.9368\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6158 - accuracy: 0.8462\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5734 - accuracy: 0.6923\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0211 - accuracy: 0.7308\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0997 - accuracy: 0.7775\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2851 - accuracy: 0.9093\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1276 - accuracy: 0.9698\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1032 - accuracy: 0.9808\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1383 - accuracy: 0.9808\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1026 - accuracy: 0.9945\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1149 - accuracy: 0.9725\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0935 - accuracy: 0.9808\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0947 - accuracy: 0.9835\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1019 - accuracy: 0.9835\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0957 - accuracy: 0.9863\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0792 - accuracy: 0.9918\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1139 - accuracy: 0.9808\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1046 - accuracy: 0.9808\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0915 - accuracy: 0.9863\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0842 - accuracy: 0.9835\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0868 - accuracy: 0.9780\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0778 - accuracy: 0.9945\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0590 - accuracy: 0.9918\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0916 - accuracy: 0.9890\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1015 - accuracy: 0.9780\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1677 - accuracy: 0.9615\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4631 - accuracy: 0.9121\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0622 - accuracy: 0.8049\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9953 - accuracy: 0.7060\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7047 - accuracy: 0.8132\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3645 - accuracy: 0.9258\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1176 - accuracy: 0.9808\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1127 - accuracy: 0.9780\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0721 - accuracy: 0.9918\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.9945\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0695 - accuracy: 0.9918\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0829 - accuracy: 0.9863\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0775 - accuracy: 0.9863\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0683 - accuracy: 0.9945\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0629 - accuracy: 0.9945\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0605 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0769 - accuracy: 0.9863\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0645 - accuracy: 0.9808\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0734 - accuracy: 0.9863\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0582 - accuracy: 0.9918\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0720 - accuracy: 0.9890\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0648 - accuracy: 0.9890\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0962 - accuracy: 0.9698\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1537 - accuracy: 0.9615\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0810 - accuracy: 0.9780\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0757 - accuracy: 0.9890\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0571 - accuracy: 0.9890\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0573 - accuracy: 0.9890\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0676 - accuracy: 0.9863\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9945\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0639 - accuracy: 0.9890\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0443 - accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "### 모델 생성하기\n",
    "model = keras.Sequential()\n",
    "model\n",
    "\n",
    "### 입력계층 추가하기(임베딩 계층 추가하기)\n",
    "#    - input_dim : 말뭉치갯수\n",
    "#    - 출력갯수 : 64개\n",
    "#    - input_length : 질문의 특성 갯수\n",
    "model.add(\n",
    "    keras.layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=64,\n",
    "                           input_length=questions_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 추가 : GRU, 출력:128, 활성화함수:relu\n",
    "# - 질문을 담당하는 계층\n",
    "model.add(\n",
    "    keras.layers.GRU(units=128, activation=\"relu\")\n",
    ")\n",
    "\n",
    "### 드롭아웃 추가\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "### 질문을 담당하는 계층에서 넘어오는 결과는 6개의 질문 특성을 사용함\n",
    "# - 답변차원의 특성 7개로 변경한 후 답변을 담당하는 계층으로 넘겨주기\n",
    "model.add(\n",
    "    keras.layers.RepeatVector(answers_train.shape[1])\n",
    ")\n",
    "\n",
    "### 은닉계층 : GRU 계층(질문 결과를 받아서 답변과의 일치성 훈련 시키기)\n",
    "# - return_sequences=True : 훈련결과(단어)를 다음 계층으로 넘겨주기\n",
    "#                         : 다음계층에서 처리결과 단어들을 받아서 연속에서 훈련 진행\n",
    "model.add(\n",
    "    keras.layers.GRU(units=128, activation=\"relu\", return_sequences=True)\n",
    ")\n",
    "\n",
    "### 단어조합 계층과 출력계층 정의하기\n",
    "# TimeDistributed \n",
    "#  - 전체 문장을 기준으로 위 계층에서 전달받은 단어들의 이전/다음 인덱스의 연결(문맥 연결)을 관리하는 계층\n",
    "#  - 다음에 올 단어들이 있는지 체크\n",
    "#  - 분류의 개념보다, 예측(회귀-시간적 흐름-단어의 문맥)의 개념을 담고있는 계층임\n",
    "#  - 출력계층을 감싸서 사용\n",
    "# ** 처리 순서 : 출력계층의 말뭉치 결과를 TimeDistributed 계층에서 확률이 높은 단어들을 조합하여 반환\n",
    "model.add(\n",
    "    keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(units=vocab_size, activation=\"softmax\")\n",
    "    )\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "### 모델 설정하기\n",
    "# - rmsprop 사용, 학습율 기존값사용, 정확도 출력\n",
    "model.compile(\n",
    "    optimizer=\"RMSprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "### 콜백함수 정의하기\n",
    "# - 파일명 : best_RNN_chatbot.h5\n",
    "save_file = \"./model/best_RNN_chatbot.h5\"\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(save_file, save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "### 훈련시키기\n",
    "# - 훈련횟수:100회, 배치사이즈:64\n",
    "history = model.fit(\n",
    "    questions_padded, answers_padded, epochs=500, batch_size=64 \n",
    "    # , validation_data=(questions_val, answers_val)\n",
    "    # , callbacks=[cp_cb, es_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e0b016",
   "metadata": {},
   "source": [
    "### 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af6dbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59 60 61  4  0  0  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('전기요금 어때?', '전기요금이 계속 인상되고 있어요')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 예측을 위한 임의 질문 정의하기\n",
    "user_input = \"전기요금 어때?\"\n",
    "\n",
    "### 텍스트 문장 내에 단어를 추출하여 -> 말뭉치 인덱스 번호로 변환하기\n",
    "# - 1차원 리스트로 넣어주기 -> 2차원 데이터로 반환해줌\n",
    "#   -> 외부 파일에서 모델을 사용하여 예측할 경우에는 말뭉치사전의 값을 알고 있어야 함\n",
    "input_seq = tokenizer.texts_to_sequences([user_input])\n",
    "\n",
    "### 데이터 스케일링 처리하기\n",
    "# - 훈련시 사용한 질문의 특성 갯수로 스케일링해야 함\n",
    "# - maxlen 속성을 정의해야 함\n",
    "#   -> 외부 파일에서 모델을 사용하여 예측할 경우에는 maxlen의 값을 알고 있어야 함\n",
    "# - truncating 속성을 정의해야 함 : 질문이 길게 입력될 수 있기 때문임\n",
    "padded_seq = pad_sequences(input_seq, padding=\"post\", truncating=\"post\",\n",
    "                           maxlen=questions_padded.shape[1])\n",
    "\n",
    "### 예측하기\n",
    "# - 말뭉치의 숫자로 예측해줌\n",
    "pred = model.predict(padded_seq)\n",
    "# print(pred)\n",
    "\n",
    "### 문자로 변환하기\n",
    "# 예측 결과 값 중에 가장 큰 값이 있는 열단위 인덱스 번호 추출하기\n",
    "# - 결과값을 리스트로 받아와야 함\n",
    "pred_index = tf.argmax(pred, axis=2).numpy()[0]\n",
    "print(pred_index)\n",
    "\n",
    "# 답변 문자(텍스트)로 변환하기\n",
    "# - 리스트를 2차원으로 넣기\n",
    "chatbot_text = tokenizer.sequences_to_texts([pred_index])[0]\n",
    "user_input, chatbot_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af6a2246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63 64 65  0  0  0  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('너 이름', '제 이름은 챗봇이에요')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 예측을 위한 임의 질문 정의하기\n",
    "user_input = \"너 이름\"\n",
    "\n",
    "### 텍스트 문장 내에 단어를 추출하여 -> 말뭉치 인덱스 번호로 변환하기\n",
    "# - 1차원 리스트로 넣어주기 -> 2차원 데이터로 반환해줌\n",
    "#   -> 외부 파일에서 모델을 사용하여 예측할 경우에는 말뭉치사전의 값을 알고 있어야 함\n",
    "input_seq = tokenizer.texts_to_sequences([user_input])\n",
    "\n",
    "### 데이터 스케일링 처리하기\n",
    "# - 훈련시 사용한 질문의 특성 갯수로 스케일링해야 함\n",
    "# - maxlen 속성을 정의해야 함\n",
    "#   -> 외부 파일에서 모델을 사용하여 예측할 경우에는 maxlen의 값을 알고 있어야 함\n",
    "# - truncating 속성을 정의해야 함 : 질문이 길게 입력될 수 있기 때문임\n",
    "padded_seq = pad_sequences(input_seq, padding=\"post\", truncating=\"post\",\n",
    "                           maxlen=questions_padded.shape[1])\n",
    "\n",
    "### 예측하기\n",
    "# - 말뭉치의 숫자로 예측해줌\n",
    "pred = model.predict(padded_seq)\n",
    "# print(pred)\n",
    "\n",
    "### 문자로 변환하기\n",
    "# 예측 결과 값 중에 가장 큰 값이 있는 열단위 인덱스 번호 추출하기\n",
    "# - 결과값을 리스트로 받아와야 함\n",
    "pred_index = tf.argmax(pred, axis=2).numpy()[0]\n",
    "print(pred_index)\n",
    "\n",
    "# 답변 문자(텍스트)로 변환하기\n",
    "# - 리스트를 2차원으로 넣기\n",
    "chatbot_text = tokenizer.sequences_to_texts([pred_index])[0]\n",
    "user_input, chatbot_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b3e10",
   "metadata": {},
   "source": [
    "- 함수 정의\n",
    "    - 함수명 : get_Answer\n",
    "    - 기능 : 질문을 받아서 예측 후 -> 텍스트로 답변을 반환 기능\n",
    "\n",
    "- 실행 프로그램 정의\n",
    "    - 무한 반복\n",
    "    - 받은 질문을 출력\n",
    "    - 답변을 출력\n",
    "    - \"Q\" 문자를 입력하면 무한반복 종료\n",
    "        - 종료 시 챗봇은 \"안녕히 가세요~\" 라고 답변\n",
    "\n",
    "- VS-Code에서 input()함수 사용시 오류 나는 경우 아래 설치\n",
    "    - pip install ipywidgets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk_dl_gpu_kernel",
   "language": "python",
   "name": "pk_dl_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
